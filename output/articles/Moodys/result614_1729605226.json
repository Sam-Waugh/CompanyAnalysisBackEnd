{
    "headline": "Automating interpretable machine learning scorecards",
    "link": "https___www_moodys_com_web_en_us_insights_resource",
    "content": "ANALYSIS Automating Interpretable\n04 SEPTEMBER, 2020\nMachine Learning Scorecards\nPrepared by\nINTRODUCTION\nOlga Loiseau-Aslanidi\nOlga.Loiseau-Aslanidi@moodys.com\nDirector Scorecard quality depends on not only model performance but also its interpretability. In this\npaper, we use our toolbox to build and compare the performance of four scorecard models.\nNatchie Subramaniam Thiagarajah\nNatchieSubramaniam.Thiagarajah@moodys.com The benchmark model leverages a modified logistic regression with constraints imposed via\nSenior Economist supervised binning and variable selection. Three challenger models are built using decision\nVera Tolstova tree, random forest and gradient boosting methods. We demonstrate that the interpretable\nVera.Tolstova@moodys.com benchmark model sacrifices little predictive power compared to the unconstrained challenger\nEconomist\nmodels. Meanwhile, the constraints are frequently violated by the challenger models, causing\ncounterintuitive results for scorecards where the interpretation is critical.\nContact Us\nEmail\nhelp@economy.com\nU.S./Canada\n+1.866.275.3266\nEMEA\n+44.20.7772.5454 (London)\n+420.224.222.929 (Prague)\nAsia/Pacific\n+852.3551.3077\nAll Others\n+1.610.235.5299\nWeb\nwww.economy.com\nwww.moodysanalytics.com\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 1Automating interpretable\nmachine learning Scorecards\nBY OLGA LOISEAU-ASLANIDI, NATCHIE SUBRAMANIAM THIAGARAJAH, AND VERA TOLSTOVA\nS\ncorecard quality depends on not only model performance but also its interpretability. In this paper, we\nuse our toolbox to build and compare the performance of four scorecard models. The benchmark model\nleverages a modified logistic regression with constraints imposed via supervised binning and variable\nselection. Three challenger models are built using decision tree, random forest and gradient boosting methods.\nWe demonstrate that the interpretable benchmark model sacrifices little predictive power compared to the\nunconstrained challenger models. Meanwhile, the constraints are frequently violated by the challenger models,\ncausing counterintuitive results for scorecards where the interpretation is critical.\nIntroduction models. Without flexible and customizable models in model fit and discriminatory pow-\nInterpretation is a key requirement for constraints, counterintuitive or unexplainable er. We show that while the gradient boosting\nrobust and tractable scorecard models for risk results may appear, and some groups of cus- and random forest models can provide supe-\nmanagement, regulatory compliance, strat- tomers may be disadvantaged when deter- rior fit to the benchmark model, they do it at\negy-setting, and product-marketing. Each mining their credit risk. the cost of violating many constraints.\ncharacteristic included in the model must not In this paper, we use our toolbox that The remainder of this paper is organized\nonly be a strong predictor that makes oper- features an ML algorithm leveraging modi- as follows. In section two, we survey the main\national sense but also comply with a priori fied logistic regression with predefined con- applications of machine learning methods\nexpectations or constraints. straints imposed via automated supervised in scorecard-building. We then describe the\nSuch constraints represent desirable binning and variable selection. We use this methodology behind our algorithmic toolbox,\npatterns and relationships between the algorithm to build a benchmark scorecard which includes binning and variable selection\npredictors and the score, based on business model that is interpretable by design. We for the benchmark model, and constraint vio-\nexperience, industry trends and regulatory then compare this model with three chal- lation assessment for the challenger models.\nrequirements. For instance, everything else lenger models built using other classifiers, In section three, we assess the performance\nbeing equal, higher-income customers are decision tree, random forest and gradient of benchmark and challenger models using\nexpected to have lower default probability; boosting methods, in terms of model per- our toolbox in terms of their performance\nthe default probability is typically higher formance and interpretability. To assess the and interpretability.\namongst unemployed individuals; and low- challenger models’ interpretability, we use\ner credit quality is associated with higher the toolbox to identify customer character- Challenges of scorecard-building\nfrequency of late payment. Characteristics istics that do not yield desired patterns and The scorecard models are designed to\nsuch as age, gender and country origin need hence violate constraints. rank-order customers by condensing the\nto comply with the fair treatment principle, Our results demonstrate that there is no variety of variables into a single score. Score-\nand monotonicity constraints can be used to significant difference in performance between card types differ by the target variable, such\nachieve the desired pattern. interpretable benchmark model and chal- as application, behavioural and collection\nNevertheless, the inclusion of various lenger classifiers models. Using different size scorecard. The models typically use the data\ntypes of constraints is not a readily available datasets for personal loans and credit cards, for customer and product characteristics,\noption in rapidly evolving scorecard-building we find that the benchmark model perfor- while alternative information such as trans-\nsetups leveraging various machine learning mance is overall slightly inferior to challenger actional data, telecommunication, rental and\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 2utilities variables can add more insight and ning and the variable\nChart 1: ML in Scorecard-Building\npredictive value. Such datasets vary by size selection algorithms\n5 Stages\nand structure. that solve optimiza-\nIndustry embraces ever-expanding and tion problems subject\ni sm cop rr eo cv ai rn dg dM evL e t le oc ph mni eq nu te , s fr a ot m v a dr aio tau s p s reta pg ae ras -of t so tr au is ne tr s- s rp eqec ui ifi ree dd ic no n- Datas Ve at ra ian bd l eTarget V Pa rr oia cb el se s P inr ge- Variable Selection Ma Oc Mh pi ton imde e iL sl e aaa tn ir odn n ing M ao nd de l M D oe np il to oy rm ine gnt\nInternal and external 1. Miss vi an lg u ea snd Null ML Models: Meta Ensemble:\nt o t t mi a hpo et etn i t i o lm haa n osn i z p t dd a o sd tv w e sia o ucer n a ci ra d h a hb e n aal ,e d ss a s gdim ne rvc al o ae r dn nec iit c eati e nsoo e d trn d i b n mt d ogo ar o. am cS sm h tio n ii nnad c getee i , cl l c neab o a elu m l r uyi nl r pd o i anui v ln g- eg r, c t u eor nse o e hd T l atbi h rt no ae ca x d esp ia dc tp l io l ol ri or ec ne w ga ac rt s la ei o ar u sd nn ss ids ot. o n DE Cteax hstp T oa til sana s ergn pd g n a dl aa e tit at b ao nt t ta i a rr dn a v gys s t s a e voe ev e r ta t d ia tts alr ir d oa bia a ni lnb et i i tl n o he g n es , SuR Km pe N- e2Np o R u r.l s Be va a mt ia i ic i sn vm m Kf nere er ade r -ne p p dro i Msw cq iu u i m nt aa du ei t tt N a a bgl i h e a sFt t lo e n ni i ceoo om o uit srsg f n nr et e v e lh ti taa hes ib zln rt eou a s re to s ior n ElaS SF sta tte aiRg ca gD ae t Nu ee n: A Ae r :c dS e n nt Mi o s i a aRin mmi uol leg y yl n p tgFs sl ie o u i t io Fs r s r lF re t a aeaea r csn ic z ttct oaeo t r ir o n HS yuM R p vpL u e iN pei an l O r Aogt e -e Ti cpv rr pu s Ra te r ra a r se otr s OVa ir r ee smi asM la e Cs s i mNMot c i o s -e z vtn Ae ed mo o a a A t te Ud rS t lw e ei il d e dM Cs o rp noa sl a l s nr taa i p tkn :t: icn ut osei hd v n ns ie in n e g p Mre ed tB aica MMts i moi oac n o Mc n a s d h io v te if on de r lo s e rer ia m l no Lg g r ee v :aa o rr nf io inu gs\nnetworks and random forests have made methodologies as 0 / 1 Nor3 m. aTD lr ize a ec n i ss oi f ro o Sn r m tt are nae dti ao rn dize Rec e Bu l eir ms si tiv n se a u tf be io sa n etu tre MinimizM eK S - CS EE r o rS; r s oM c s ro A VreE alidation TraD inca k ss m hh oab o rno d to a e tm or l d pa l oet lo i nre f gsd o e r temte ra mc nt ce\ntheir way into credit-scoring models. These well as alternative\nmethods have demonstrated their superiority ML methods. Such\nSource: Moody’s Analytics\nin the speed of the scorecard-building process an approach allows\nand often predictive power compared to the us to focus on key May 2020 1\ntraditional logistic regression approach, see decisions, while relegating the tedious, com- constraints, logical patterns, business\nEfron & Hastie (2016) and Alpaydin (2020), plex tasks of binning, variable selection, and expectations, and compliance with\namong others. More complex classifier meth- the constraints violations assessment to equal credit opportunity legal acts for\nods have proven to be especially superior in automated algorithms. customer age or gender. For example,\nlarge unstructured datasets with many pre- a monotone or quadratic relationship\ndictors. Chart 1 summarises applications of Binning algorithm between binned predictors and default\nmachine learning in scorecard-building. Binning is a first step in scorecard model rate can be incorporated as a con-\nHowever, many advanced machine learn- development. It transforms the values of var- straint when splitting variable values\ning methods suffer from a lack of tractability ious types of potential predictors into several into bins.\nand interpretability of model structure and groups, known as bins, according to specified\npredictions. The “interpretable” trend in criteria. Binning is applied to numerical data » Capture non-linear relationships.\nML model development has been gaining such as customer age or income, categorical Binning allows us to capture non-lin-\nmore attention, see, for example, Gilpin et al data such as loan purpose or property type, earities in a data-driven way, without\n(2018) and Rudin (2019). Although there are and ordinal data that has defined ordering, making restrictive parametric assump-\nsome methods that enable us to peek into such as customer education or employ- tions. For example, account age may\nthe black box, there is still no consensus on ment status. The result of binning is a set of have a non-linear relationship with the\nhow to assess the interpretation quality. 1 As “binned” variables for the next step in model default rate.\nthe interpretability translates into a set of development, the variable selection.\nconstraints, algorithmic solutions for more The key advantages of binning include » Model accuracy by handling outliers\ncomplex ML methodologies are challenging. » Simplicity and business tractability. and missing values. Binning mitigates\nThese issues have been recognized by indus- Binning is used to simplify the model the impact of outliers and missing\ntry and regulators worldwide, who called predictors by creating groups that have values by grouping observations.\nfor the responsible use of ML to ensure the expected patterns and relationships Grouping of similar attributes with\nprinciples of fairness, ethics, accountability with the target variable. For instance, similar predictive strengths increases\nand transparency when assessing customers’ low-income customers are expected the model’s accuracy. For example,\ncredit risk. to have higher default rates than high- the procedure extracts information\nRecognizing the need for a scorecard to er-income customers. Hence, it makes from such observations into a sep-\nbe interpretable, transparent, and able to sense to split the numerical income arate bin and uses it to predict the\nwithstand regulatory scrutiny, we have de- values into several bins. Including target variable.\nsigned an automated algorithmic toolbox. binned variables allows us to evaluate\nThe scorecard toolbox includes tools for data only a few logical conditions to calcu- In practice, binning procedures vary de-\nanalysis, model development and assess- late the score, instead of calculating pending on data and model characteristics.\nment, model validation, model refinement, the score for each possible combina- Binning can be based on expert opinion, uti-\nscoring, model-monitoring, and strategy-set- tion of predictor values. lize unsupervised or supervised algorithms\nting. At the core of this toolbox are the bin- with quantitative optimization techniques,\n» Flexibility to incorporate con- or use a combination of these. Typically,\n1 For example, Lundberg and Lee (2017) developed Shapley straints. Binning can be formulated many manual interventions and visual as-\nAdditive Explanations to interpret the output of machine with various types of constraints. sessments of the binning solution’s quality\nlearning models, while Carvalho et al (2019) provide a re-\nview of machine learning models’ interpretability. These constraints include binning size are required.\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 3Chart 2: Constraints for Ordinal Data\n5\n4\n3\n2\n1\n0\n< 100 100 ≤ to < 500 500 ≤ to < 1,000 ≥ 1,000\nSource: Moody’s Analytics\nMay 2020 2\nThe main idea of supervised binning is toolbox implements both monotone of confidence interval to assess the\nto find optimal cut-off points to define bins (such as decreasing, increasing) and discriminatory power of the selected\nsubject to various types of constraints. Some non-monotone (such as u-shaped, bins. To improve the quality of binning,\nconstraints are required to ensure each hump-shaped) types of relationship the algorithm considers not only the\nbin strikes a balance between being “wide between the binned variable and target point estimate but also a confidence\nenough” and “narrow enough” by having variable. Moreover, the toolbox allows interval for the default rate of each bin.\ndistinctly different risk characteristics with for the incorporation of the constraints For example, when confidence inter-\nminimum information loss. Examples include for ordinal variables based on the us- vals for each bin overlap, the chosen\ncontrolling the number of bins, the number er-provided order of labels. bins may not have enough power to\nof observations in each bin, and non-over- Charts 2 and 3 illustrate an example discriminate between defaulted and\nlapping confidence intervals for default rates of implementing constraints for ordi- non-defaulted observations.\nof each bin. In addition, a critical aspect of nal data for available savings. Chart 2 As illustrated in Charts 4 and 5,\nbinning is the enforcement of various types shows the preferred order of the cate- the algorithm combines such bins to\nof constraints representing requirements that gories specified by the user: The default achieve an optimal solution. Chart 4\ncertain patterns must emerge when calculat- rates follow a non-increasing trend shows an example binning solution\ning the scores. across categories as lower savings are with overlapping confidence inter-\nOur toolbox automates the tedious as- associated with worse credit quality. vals for the 3rd and 4th bins. Chart 5\npects of supervised binning, allowing the Chart 3 demonstrates the solution demonstrates the toolbox solution that\nanalyst to specify options and preferences. by the supervised binning algorithm satisfies the constraint on non-over-\nThe supervised binning algorithm solves an obtained in line with this imposed lapping intervals. In this example,\noptimization problem with user-defined con- assumption. The categories “100 ≤ this is achieved by merging intervals\nstraints, while controlling the number and to < 500”, “500 ≤ to < 1,000” and “≥ “10,847 to 14,803” and “>14,803” into\ndiscriminatory power of resulting bins. The 1,000” are merged, but the desired “>10,847”.\nprocedure significantly reduces the time costs ordering is pre-\nof generating predictive characteristics. served as the\nChart 4: Confidence Intervals Merging\nThe key ingredients of our supervised bin- trend in default\nning algorithm include rates is indeed Default rate\n» Maximize binned variable’s predic- non-increasing. 100%\ntive power. User-defined performance » Control num- 80% Overlapping confidence intervals\nmetrics such as information value, Gini ber, size and 60%\nand chi-square statistics to assess vari- discriminatory 40%\nable’s predictive power. power for 20%\nselected bins. 0%\n» Comply with constraints. User-de- Users can con-\nfined constraints and label-ordering trol the number\nfor ordinal variables are incorporated and size of\ninto the optimization algorithm. These bins as well\nconstraints represent expected trends as specify the\nin the default rates across bins. The threshold level Source: Moody’s Analytics\nMay 2020 4\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 4\nredrO\nChart 3: Constraints for Ordinal Data\nAssumption\n40%\n35%\n30%\n25%\n20%\n15%\n10%\n5%\n0%\n< 100 ≥ 100\nSource: Moody’s Analytics\nMay 2020 3\netar\ntluafeD\nSolutionChart 5: Confidence Intervals Merging Chart 6: A Simple Decision Tree Example\nDefault rate\n100%\nDuration in mo<122\n80%\n60% Yes No\n40%\n20%\nCredit amount Credit amount\n0% <34,222 <14,002\nYes No Yes No\n0.25 0.34 0.46 0.39\nSource: Moody’s Analytics Source: Moody’s Analytics\nMay 2020 5 May 2020 6\nVariable selection algorithm variables enter the model has a significant to assess models’ tractability. Our toolbox\nAs a next step of the model-building impact on the final model that may result in provides several options to identify the\nprocess, the variable selection algorithm is overfitting, dependence on training sample constraints violations for these machine\nused to identify the characteristics to in- selection, or that may eliminate variables learning models.\nclude into the regression model. The binned that would provide additional informa- In the case of decision tree, it is feasible\ncandidate variables obtained at the previous tion and improve model performance, see to extract all tree nodes. We calculate the\nbinning stage can be used as inputs into the Altman & Anderson (1989) and Audrino average probability of default for each vari-\nvariable selection procedure to define the & Kanus (2016) among others. Second, able interval determined by tree cut points.\nmodel specification. stepwise regression does not consider the If the variable appears at different tree\nIn practice, various methodologies are possible correlations between the variables. branches several times, the average default\nused for the variable selection in various Nor does this algorithm consider constraints probability is calculated based on all internal\ntypes of risk models. Brute-force algorithms such as logical patterns based on business and leaf nodes, taking into consideration in-\nexhaustively evaluate all possible combi- experience, industry trends, or legally teraction terms. This procedure is analogous\nnations of candidate predictors to find the required relationships. to evaluating the type of the relationship\nbest subset. These algorithms can be mod- In our toolbox, we enhance the stepwise in the case of binning and is, therefore,\nified to incorporate constraints. Dynamic algorithm by offering capabilities to speci- straightforward to use for evaluation of the\ncredit risk models with linkages to macro- fy user preferences on dependencies. Such constraint’s violation. A simple tree exam-\neconomic as well as portfolio characteristics constraints may include the expected rela- ple illustrating the procedure is shown in\nare good examples when such procedures tionships between characteristics and the Chart 6.\nwork well, see Licari, Loiseau-Aslanidi and target variable, statistical significance of the In the case of random forest and gradient\nVikhrov (2017). variables, and maximum allowed value of boosting, the extraction of all tree nodes and\nAlternative variable selection procedures pairwise correlation. These constraints may splits is not the best solution because of their\nare preferred when the number of candidate be imposed either on coefficients’ estimates complicated model structure. We rely on\ncharacteristics and number of observations signs or their order. After the model is built, the Shapley values approach used to assess\nis so large that it makes the exhaustive the validation is performed, and an iterative the marginal contributions of various drivers\nsearch’s computational cost prohibitively model refinement algorithm sequential- into predicted probability of default values.\nhigh. Stepwise algorithms such as forward ly excludes variables that do not comply Because of the potentially very large number\nstepwise have the advantage of relatively with the constraints from a list of initial of cut points for continuous variables, the\nhigh execution speed, as they rely on a se- potential drivers. evaluation of trend monotonicity based on\nquence of nested models as opposed to the the average default rates for each bin may\nbrute-force exhaustive search. Not surpris- Assessing constraints violation for not be applicable.\ningly, forward stepwise regression is a work- challenger models To facilitate comparability of the results\nhorse variable selection procedure in credit The scorecard model designed using with a logistic regression model, we focus on\nrisk scoring. the steps outlined above is designed to evaluation of the constraints only for ordi-\nNevertheless, classical stepwise meth- satisfy user-defined constraints imposed nal variables and calculate average Shapley\nods require enhancements to improve their at the supervised binning and the variable values for each category. Additionally, the\nefficiency and applicability for scorecards. selection stages. In contrast, decision tree, toolbox provides a standard heat map of\nFirst, the stepwise algorithm is not robust random forest and gradient boosting chal- Shapley values for various realizations of\nto variable ordering. The order in which lenger models need an additional analysis each driver.\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 5Models Assessment For each realization of the Table 1: Summary of Dataset\ntrain dataset, we build four alter-\nData and methodology native models. The first model Country Germany Taiwan\nTo assess and compare the performance is a benchmark built using the Product type Personal loans Credit cards\nof several ML models, we conduct an em- algorithmic supervised binning Number of observations 1,000 30,000\npirical study using two datasets that differ and modified weight-of-evidence Number of characteristics 24 23\nNumber of defaults 300 6,636\nby product type, geography and size. Both logistic regression with example\ndatasets cover consumer credit portfolios constraints presented in Table 2.\nSources: UCI Machine Learning Repository, Moody’s Analytics\nfrom the UCI Machine Learning Repository2, Next, we use decision tree, ran-\nwhich is frequently used in studies on per- dom forest and gradient boosting\nformance evaluation of machine learning of decision trees with least-squares loss func- Model performance and interpretability\nand data mining algorithms. The first data- tion as three challenger models. assessment\nset covers a German fixed-term portfolio For the latter models, it is crucial to We use standard measures to evaluate\nfor personal loans, while the second dataset properly tune hyper-parameters to prevent the models’ performance, and we assess\ncovers a credit cards portfolio in Taiwan (see overfitting. We tune hyper-parameters models’ interpretability by looking into\nTable 1). through stratified k-fold cross validation with constraints violations. The accuracy of the\nWe begin by splitting each dataset into application of exhaustive grid search over model fit is measured by the Brier score,\ndevelopment (train) and holdout (test) in various parameter combinations to maximize while the discriminatory power is assessed\na standard proportion 70:30. To mitigate a the average accuracy ratio on validation through Gini or the area under the curve\nsample-dependency bias for model perfor- subsamples. For the RF model, the procedure (see Table 3).\nmance measures, especially for the German optimizes the maximum depth of trees and We observe that enforcing constraints\ndataset consisting of only 1,000 observations, number of estimators. For the GB model, the on the benchmark model has little impact\nwe generate 100 train and test subsets reali- set of optimized parameters is broader, and on the performance, and for brevity we do\nzations without replacement. along with maximum depth and number of not report the results of the benchmark\ntrees it includes the learning rate and subsa- model without constraints. Moreover, the\nmple size to be selected for the estimation of benchmark regression model with supervised\n2 This is a real-life credit scoring dataset publicly available at\nthe UCI repository at http://kdd.ics.uci.edu/. each tree. binning and constraints demonstrates similar\nTable 2: Selected Example Constraints for Model Interpretation Evaluation\nVariable Product type Variable type Trend Order of labels for ordinal variables\nDuration in mo Personal loans Numerical Monotonic\n< 100, 100 <= ... < 500, 500 <= ... < 1000, >=\nSavings account amount Personal loans Ordinal Negative 1000\nCredit amount Personal loans Numerical Positive\nUnemployed, ... < 1 yr, 1 <= ... < 4, 4 <= ... <\nPresent employment since (employment longevity) Personal loans Ordinal Negative 7, >= 7 yrs\nInstallment rate Personal loans Numerical Monotonic\nOther debtors Personal loans Ordinal Negative None, co-applicant, guarantor\nPresent residence since Personal loans Numerical Negative\nHousing type Personal loans Ordinal Negative For free, rent, own\nNumber of existing credits Personal loans Numerical Positive\nUnemployed, unskilled, unskilled resident,\nskilled employee, official, management,\nself-employed, highly qualified employee,\nJob Personal loans Ordinal Negative officer\nNumber of people being liable Personal loans Numerical Negative\nYes, registered under the customer’s name,\nTelephone Personal loans Ordinal Positive none\nAmount of given credit Credit cards Numerical Positive\nNA, high school, others, university, graduate\nEducation Credit cards Ordinal Negative school\nPast payment status in Apr-Sep 2005 Credit cards Ordinal Positive\nAmount of bill statement (balance) in Apr-Sep 2005 Credit cards Numerical Monotonic\nAmount of previous payment in Apr-Sep 2005 Credit cards Numerical Monotonic\nSource: Moody’s Analytics\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 6Table 3: Summary of Model Performance tember and August) past payment status\nand previous payments. The rest of the lags\nPersonal loans Credit cards are not selected by the models because of\nGini Brier score Gini Brier score the absorbing properties of the most recent\nWOE logistic with supervised binning with constraints 0.519 0.175 0.525 0.139 observations. As expected, the constraints\nDecision tree 0.417 0.198 0.41 0.14 are not violated in the DT model because of\nRandom forest 0.513 0.177 0.567 0.132\nthe relatively shallow trees produced by the\nGradient boosting 0.544 0.173 0.562 0.133\nalgorithm, while the constraints are violated\nfor the RF and GB models.\nSource: Moody’s Analytics\nThe illustration of constraints violations\nfor employment status is depicted in Charts\nperformance to the challenger ML models.3 loans, the constraints are violated for six out 7-10. In contrast to the benchmark model\nThe GB model performs slightly better for of 10 variables that appear in the DT model. with supervised binning, where lower default\npersonal loans, while for credit cards the For example, the credit amount and the num- rates are associated with longer duration of\nRF model outperforms the others. The DT ber of existing credits do not have the expect- employment, the models using the DT, RF\nmodel’s performance is inferior for both ed positive relationship with the default rate. and GB methods show counterintuitive rela-\nproduct types. Similarly, the employment longevity and job tionships. The DT model predicts a lower de-\nTo evaluate the models’ interpretability, description ordering are counterintuitive, re- fault rate for the categories with unemployed\nthe violation of constraints is evaluated for sulting in the unemployed customers having and shorter employment duration than for\nthe challenger DT, RF and GB models (see Ta- lower default rates than those with years of categories with longer employment duration.\nble 4). The benchmark model satisfies all the employment. For the RF and GB models, all Both the RF and GB models predict lower\nconstraints by design. In the case of personal the constraints are violated, with the employ- default rate for the “Unemployed” versus the\nment-related variables having the highest 1-year employment duration categories. Ad-\n3 We compare performance based on the accuracy of their percentage of violation cases. ditionally, the RF model predicts a somewhat\npredictions on the test dataset. Model performance on train In the case of credit cards, the selected lower default rate for four to seven years than\ndatasets cannot be used for an objective model evaluation\nsince that dataset was used for model development. variables represent the most recent (Sep- for seven years or more.\nTable 4: Frequency of the Example Constraints Violation\n% of violated % of violated % of violated\nConstraint variables Data Variable type % of appearance, DT cases, DT cases, RF cases, GB\nDuration in mo Personal loans Numerical 100 0\nCredit amount Personal loans Numerical 95 26.32 - -\nPresent employment since Personal loans Ordinal 50 16 92 93\nOther debtors Personal loans Ordinal 32 0 62 52\nSavings account amount Personal loans Ordinal 26 0 66 39\nInstallment rate Personal loans Numerical 22 0 - -\nPresent residence since Personal loans Numerical 25 92 86 97\nHousing type Personal loans Ordinal 0 - 33 52\nJob Personal loans Ordinal 5 60 91 91\nTelephone Personal loans Ordinal 7 42.86 64 31\nNumber of existing credit Personal loans Numerical 3 100 - -\nNumber of people being liable Personal loans Numerical 0 - - -\nEducation Credit cards Ordinal 0 - 0 100\nPast payment status in Sep 2005 Credit cards Ordinal 100 0 100 100\nPast payment status in Aug 2005 Credit cards Ordinal 100 0 100 100\nPast payment status in Jul 2005 Credit cards Ordinal 0 - 100 100\nPast payment status in Jun 2005 Credit cards Ordinal 0 - 100 100\nPast payment status in May 2005 Credit cards Ordinal 0 - 100 100\nPast payment status in Apr 2005 Credit cards Ordinal 0 - 100 100\nAmount of previous payment in Sep 2005 Credit cards Numerical 6 0 - -\nAmount of previous payment in Aug 2005 Credit cards Numerical 28 0 - -\nAmount of previous payment in Jul 2005 Credit cards Numerical 1 0 - -\nAmount of previous payment in Apr-Jun 2005 Credit cards Numerical 0 0 - -\nAmount of bill statement (balance) in Apr-Sep 2005Credit cards Numerical 0 0 - -\nSource: Moody’s Analytics\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 7Chart 7: Default Rates vs. Employment Chart 8: Default Rates vs. Employment\nDefault rate, constraint logit Default rate, decision tree\n40% 80%\n30% 60%\n20% 40%\n10% 20%\n0% 0%\nUnemployed, < 4 yrs ≥ 4 yrs Unemployed, < 7 yrs ≥ 7 yrs\nSource: Moody’s Analytics Source: Moody’s Analytics\nMay 2020 7 May 2020 8\nChart 9: Shapley Values vs. Employment Chart 10: Shapley Values vs. Employment\nAvg Shapley value, random forest Avg Shapley value, gradient boosting\n1.2% 3%\n0.8% 2%\n0.4% 1%\n0.0% 0%\n-0.4% -1%\n-0.8% -2%\nSource: Moody’s Analytics Source: Moody’s Analytics\nMay 2020 9 May 2020 10\nConclusion in supervised binning and variable selection the high risk of constraints violation. The\nUsing our automated toolbox, we de- algorithms for the benchmark model. The challenger models produce counterintui-\nsigned and compared several models in terms toolbox is also used to assess the chal- tive results for some model characteristics,\nof their performance and interpretability. The lenger ML models’ results by looking into making further model refinements neces-\nconsidered models include the benchmark constraints violations. sary before the model is implemented for\nmodel leveraging modified logistic regression We demonstrated that our benchmark decision-making.\nwith supervised binning, and three challenger model achieves somewhat similar perfor- Our algorithmic tools to build the bench-\nmodels using the decision tree, random forest mance to the challenger ML models, while mark model allow for a reasonable com-\nand gradient boosting methods. being easily interpretable and satisfying promise between the automation to reduce\nModels’ interpretability is represented imposed constraints by default. Although manual intervention and minimize the time\nby a set of constraints. The key feature of the gradient boosting and random forest and costs of model development, and the\nthe used toolbox is the broad type of us- models slightly outperform the benchmark model interpretation that is critical in credit\ner-defined customizable constraints used model, this is achieved at the expense of scoring applications.\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 8references\nAlpaydin, E. (2020). Introduction to machine learning. MIT press.\nAltman, D., & Anderson, P. (1989). Bootstrap investigation of a Cox regression model. Statistics in Medicine, 8(7), 771-83.\nAnderson, R. (2007). The credit scoring toolkit: theory and practice for retail credit risk management and decision automation. Oxford University Press.\nAudrino, F., & Kanus, S. (2016). Lassoing the HAR Model: A Model Selection Perspective on Realized Volatility Dynamics. Econometric Reviews, 35, 1485-1521.\nCarvalho, D. V., Pereira, E. M., & Cardoso, J. S. (2019). Machine learning interpretability: A survey on methods and metrics. Electronics, 8(8), 832.\nDua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Sci-\nence.\nEfron, B., & Hastie, T. (2016). Computer age statistical inference (Vol. 5). Cambridge University Press.\nGilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M., & Kagal, L. (2018). Explaining explanations: An approach to evaluating interpretability of machine learning. arXiv\npreprint arXiv:1806.00069.\nLicari, J. M., Loiseau-Aslanidi, O., & Vikhrov, D. (2017). Dynamic Model-Building: A Proposed Variable Selection Algorithm. Moody’s Analytics Risk Perspectives. Volume IX.\nLundberg, S. M., & Lee, S. I. (2017). A unified approach to interpreting model predictions. In Advances in neural information processing systems (pp. 4765-4774).\nRudin, C. (2019). Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5),\n206-215.\nSiddiqi, N. (2017). Intelligent credit scoring: Building and implementing better credit risk scorecards. John Wiley & Sons.\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 9About the Authors\nOlga Loiseau-Aslanidi is the head of risk modelling of Economics and Business Analytics APAC, based in the Singapore office. She manages a team of economists and\nrisk modelers in Prague, Shanghai and Sydney who design models for forecasting and simulation, with an emphasis on stress-testing for three key areas: macroeconomic\nmodels, market risk, and credit portfolio risk. During her time at Moody’s based in Europe and now in Asia, Olga has led consulting projects with major banks and other\nfinancial institutions worldwide focusing on stress-testing, including CCAR, EBA, PRA as well as IFRS 9, IRRBB and IRB model design and implementation. She is directly\ninvolved in the research and implementation of Moody’s Analytics risk management solutions for market risk and retail credit risk modelling, and often speaks at credit\nevents and economic conferences worldwide, communicating the team’s research and methodologies to the market. Before joining Moody’s Analytics, she worked for\nthe Academy of Sciences of the Czech Republic and at a consultancy firm focused on macroeconomic forecasting and analysis of emerging market economies. She has\npublished several academic articles and has been teaching graduate courses in economics, statistics and econometrics. She holds a PhD and an MA in economics and\neconometrics from Charles University (CERGE-EI), following studies for an MSc in mathematics and a BSc with honors in applied mathematics.\nNatchie Subramaniam Thiagarajah is an associate director at Moody’s Analytics and a member of the Credit Analytics group. Subra is involved in developing and\nvalidating credit risk models. Before joining Moody’s Analytics, Subra was a senior associate at Discover Financial Services, where he did model validation and research.\nSubra holds a PhD in economics and an MS in agricultural economics from the University of Arizona. Subra completed his BS in agricultural economics at the University of\nPeradeniya in Sri Lanka.\nVera Tolstova is an economist in the Prague office. She is responsible for leading advisory projects involving credit and market risk and IFRS 9 and stress-testing model de-\nvelopment and validation with banks and international financial institutions. Additionally, Vera and her team work on developing methodologies and numerical algorithms\nfor credit risk PD, LGD, EAD and IRB modelling involving automatized binning, variable selection and machine learning methods for credit risk scorecards, hybrid scorecards\ncombining both quantitative and expert judgment scores as well as forecast performance analysis according to IFRS 9 methodology. Prior to joining Moody’s, Vera was\nworking as a junior researcher at the Center of Economic Research and Graduate Education (CERGE-EI) in Prague and as an analyst at one of the leading Russian pharma-\nceutical distributors. She received her MA in economics from CERGE-EI in 2014, following master’s and bachelor’s degrees in economics from Novosibirsk State University,\nRussia, and is currently working on her PhD dissertation thesis with a focus on dynamic macroeconomics with heterogeneous agents, public policy and family economics.\nMOODY’S ANALYTICS AutomAting interpretAble mAchine leArning ScorecArdS 10About Moody’s Analytics\nMoody’s Analytics provides fi nancial intelligence and analytical tools supporting our clients’ growth, effi ciency\nand risk management objectives. The combination of our unparalleled expertise in risk, expansive information\nresources, and innovative application of technology helps today’s business leaders confi dently navigate an\nevolving marketplace. We are recognized for our industry-leading solutions, comprising research, data, software\nand professional services, assembled to deliver a seamless customer experience. Thousands of organizations\nworldwide have made us their trusted partner because of our uncompromising commitment to quality, client\nservice, and integrity.\nConcise and timely economic research by Moody’s Analytics supports fi rms and policymakers in strategic planning, product\nand sales forecasting, credit risk and sensitivity management, and investment research. Our economic research publications\nprovide in-depth analysis of the global economy, including the U.S. and all of its state and metropolitan areas, all European\ncountries and their subnational areas, Asia, and the Americas. We track and forecast economic growth and cover specialized\ntopics such as labor markets, housing, consumer spending and credit, output and income, mortgage activity, demographics,\ncentral bank behavior, and prices. We also provide real-time monitoring of macroeconomic indicators and analysis on timely\ntopics such as monetary policy and sovereign risk. Our clients include multinational corporations, governments at all levels,\ncentral banks, fi nancial regulators, retailers, mutual funds, fi nancial institutions, utilities, residential and commercial real\nestate fi rms, insurance companies, and professional investors.\nMoody’s Analytics added the economic forecasting fi rm Economy.com to its portfolio in 2005. This unit is based in West Chester\nPA, a suburb of Philadelphia, with offi ces in London, Prague and Sydney. More information is available at www.economy.com.\nMoody’s Analytics is a subsidiary of Moody’s Corporation (NYSE: MCO). Further information is available at\nwww.moodysanalytics.com.\nDISCLAIMER: Moody’s Analytics, a unit of Moody’s Corporation, provides economic analysis, credit risk data and insight,\nas well as risk management solutions. Research authored by Moody’s Analytics does not refl ect the opinions of Moody’s\nInvestors Service, the credit rating agency. To avoid confusion, please use the full company name “Moody’s Analytics”, when\nciting views from Moody’s Analytics.\nAbout Moody’s Corporation\nMoody’s Analytics is a subsidiary of Moody’s Corporation (NYSE: MCO). MCO reported revenue of $4.8 billion in 2019,\nemploys more than 11,000 people worldwide and maintains a presence in more than 40 countries. Further information\nabout Moody’s Analytics is available at www.moodysanalytics.com.© 2020 Moody’s Corporation, Moody’s Investors Service, Inc., Moody’s Analytics, Inc. and/or their licensors and affi liates (collectively, “MOODY’S”). All\nrights reserved.\nCREDIT RATINGS ISSUED BY MOODY’S INVESTORS SERVICE, INC. AND ITS RATINGS AFFILIATES (“MIS”) ARE MOODY’S CURRENT OPIN-\nIONS OF THE RELATIVE FUTURE CREDIT RISK OF ENTITIES, CREDIT COMMITMENTS, OR DEBT OR DEBT-LIKE SECURITIES, AND MOODY’S\nPUBLICATIONS MAY INCLUDE MOODY’S CURRENT OPINIONS OF THE RELATIVE FUTURE CREDIT RISK OF ENTITIES, CREDIT COMMIT-\nMENTS, OR DEBT OR DEBT-LIKE SECURITIES. MOODY’S DEFINES CREDIT RISK AS THE RISK THAT AN ENTITY MAY NOT MEET ITS CONTRAC-\nTUAL, FINANCIAL OBLIGATIONS AS THEY COME DUE AND ANY ESTIMATED FINANCIAL LOSS IN THE EVENT OF DEFAULT. CREDIT RATINGS\nDO NOT ADDRESS ANY OTHER RISK, INCLUDING BUT NOT LIMITED TO: LIQUIDITY RISK, MARKET VALUE RISK, OR PRICE VOLATILITY.\nCREDIT RATINGS AND MOODY’S OPINIONS INCLUDED IN MOODY’S PUBLICATIONS ARE NOT STATEMENTS OF CURRENT OR HISTORICAL\nFACT. MOODY’S PUBLICATIONS MAY ALSO INCLUDE QUANTITATIVE MODEL-BASED ESTIMATES OF CREDIT RISK AND RELATED OPINIONS\nOR COMMENTARY PUBLISHED BY MOODY’S ANALYTICS, INC. CREDIT RATINGS AND MOODY’S PUBLICATIONS DO NOT CONSTITUTE OR\nPROVIDE INVESTMENT OR FINANCIAL ADVICE, AND CREDIT RATINGS AND MOODY’S PUBLICATIONS ARE NOT AND DO NOT PROVIDE\nRECOMMENDATIONS TO PURCHASE, SELL, OR HOLD PARTICULAR SECURITIES. NEITHER CREDIT RATINGS NOR MOODY’S PUBLICATIONS\nCOMMENT ON THE SUITABILITY OF AN INVESTMENT FOR ANY PARTICULAR INVESTOR. MOODY’S ISSUES ITS CREDIT RATINGS AND PUB-\nLISHES MOODY’S PUBLICATIONS WITH THE EXPECTATION AND UNDERSTANDING THAT EACH INVESTOR WILL, WITH DUE CARE, MAKE\nITS OWN STUDY AND EVALUATION OF EACH SECURITY THAT IS UNDER CONSIDERATION FOR PURCHASE, HOLDING, OR SALE.\nMOODY’S CREDIT RATINGS AND MOODY’S PUBLICATIONS ARE NOT INTENDED FOR USE BY RETAIL INVESTORS AND IT WOULD BE RECKLESS\nAND INAPPROPRIATE FOR RETAIL INVESTORS TO USE MOODY’S CREDIT RATINGS OR MOODY’S PUBLICATIONS WHEN MAKING AN INVESTMENT\nDECISION. IF IN DOUBT YOU SHOULD CONTACT YOUR FINANCIAL OR OTHER PROFESSIONAL ADVISER.\nALL INFORMATION CONTAINED HEREIN IS PROTECTED BY LAW, INCLUDING BUT NOT LIMITED TO, COPYRIGHT LAW, AND NONE OF SUCH IN-\nFORMATION MAY BE COPIED OR OTHERWISE REPRODUCED, REPACKAGED, FURTHER TRANSMITTED, TRANSFERRED, DISSEMINATED, REDISTRIB-\nUTED OR RESOLD, OR STORED FOR SUBSEQUENT USE FOR ANY SUCH PURPOSE, IN WHOLE OR IN PART, IN ANY FORM OR MANNER OR BY ANY\nMEANS WHATSOEVER, BY ANY PERSON WITHOUT MOODY’S PRIOR WRITTEN CONSENT.\nAll information contained herein is obtained by MOODY’S from sources believed by it to be accurate and reliable. Because of the possibility of human\nor mechanical error as well as other factors, however, all information contained herein is provided “AS IS” without warranty of any kind. MOODY’S\nadopts all necessary measures so that the information it uses in assigning a credit rating is of suffi cient quality and from sources MOODY’S considers to\nbe reliable including, when appropriate, independent third-party sources. However, MOODY’S is not an auditor and cannot in every instance indepen-\ndently verify or validate information received in the rating process or in preparing the Moody’s publications.\nTo the extent permitted by law, MOODY’S and its directors, offi cers, employees, agents, representatives, licensors and suppliers disclaim liability to any\nperson or entity for any indirect, special, consequential, or incidental losses or damages whatsoever arising from or in connection with the information\ncontained herein or the use of or inability to use any such information, even if MOODY’S or any of its directors, offi cers, employees, agents, representatives,\nlicensors or suppliers is advised in advance of the possibility of such losses or damages, including but not limited to: (a) any loss of present or prospective\nprofi ts or (b) any loss or damage arising where the relevant fi nancial instrument is not the subject of a particular credit rating assigned by MOODY’S.\nTo the extent permitted by law, MOODY’S and its directors, offi cers, employees, agents, representatives, licensors and suppliers disclaim liability for\nany direct or compensatory losses or damages caused to any person or entity, including but not limited to by any negligence (but excluding fraud, will-\nful misconduct or any other type of liability that, for the avoidance of doubt, by law cannot be excluded) on the part of, or any contingency within or\nbeyond the control of, MOODY’S or any of its directors, offi cers, employees, agents, representatives, licensors or suppliers, arising from or in connection\nwith the information contained herein or the use of or inability to use any such information.\nNO WARRANTY, EXPRESS OR IMPLIED, AS TO THE ACCURACY, TIMELINESS, COMPLETENESS, MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR\nPURPOSE OF ANY SUCH RATING OR OTHER OPINION OR INFORMATION IS GIVEN OR MADE BY MOODY’S IN ANY FORM OR MANNER\nWHATSOEVER.\nMoody’s Investors Service, Inc., a wholly-owned credit rating agency subsidiary of Moody’s Corporation (“MCO”), hereby discloses that most issuers\nof debt securities (including corporate and municipal bonds, debentures, notes and commercial paper) and preferred stock rated by Moody’s Investors\nService, Inc. have, prior to assignment of any rating, agreed to pay to Moody’s Investors Service, Inc. for appraisal and rating services rendered by it fees\nranging from $1,000 to approximately $2,700,000. MCO and MIS also maintain policies and procedures to address the independence of MIS’s ratings\nand rating processes. Information regarding certain affi liations that may exist between directors of MCO and rated entities, and between entities who\nhold ratings from MIS and have also publicly reported to the SEC an ownership interest in MCO of more than 5%, is posted annually at www.moodys.\ncom under the heading “Investor Relations — Corporate Governance — Director and Shareholder Affi liation Policy.”\nAdditional terms for Australia only: Any publication into Australia of this document is pursuant to the Australian Financial Services License of MOODY’S\naffi liate, Moody’s Investors Service Pty Limited ABN 61 003 399 657AFSL 336969 and/or Moody’s Analytics Australia Pty Ltd ABN 94 105 136 972\nAFSL 383569 (as applicable). This document is intended to be provided only to “wholesale clients” within the meaning of section 761G of the Corpora-\ntions Act 2001. By continuing to access this document from within Australia, you represent to MOODY’S that you are, or are accessing the document\nas a representative of, a “wholesale client” and that neither you nor the entity you represent will directly or indirectly disseminate this document or its\ncontents to “retail clients” within the meaning of section 761G of the Corporations Act 2001. MOODY’S credit rating is an opinion as to the creditwor-\nthiness of a debt obligation of the issuer, not on the equity securities of the issuer or any form of security that is available to retail investors. It would\nbe reckless and inappropriate for retail investors to use MOODY’S credit ratings or publications when making an investment decision. If in doubt you\nshould contact your fi nancial or other professional adviser.\nAdditional terms for Japan only: Moody’s Japan K.K. (“MJKK”) is a wholly-owned credit rating agency subsidiary of Moody’s Group Japan G.K., which is\nwholly-owned by Moody’s Overseas Holdings Inc., a wholly-owned subsidiary of MCO. Moody’s SF Japan K.K. (“MSFJ”) is a wholly-owned credit rating\nagency subsidiary of MJKK. MSFJ is not a Nationally Recognized Statistical Rating Organization (“NRSRO”). Therefore, credit ratings assigned by MSFJ\nare Non-NRSRO Credit Ratings. Non-NRSRO Credit Ratings are assigned by an entity that is not a NRSRO and, consequently, the rated obligation will\nnot qualify for certain types of treatment under U.S. laws. MJKK and MSFJ are credit rating agencies registered with the Japan Financial Services Agency\nand their registration numbers are FSA Commissioner (Ratings) No. 2 and 3 respectively.\nMJKK or MSFJ (as applicable) hereby disclose that most issuers of debt securities (including corporate and municipal bonds, debentures, notes and\ncommercial paper) and preferred stock rated by MJKK or MSFJ (as applicable) have, prior to assignment of any rating, agreed to pay to MJKK or MSFJ (as\napplicable) for appraisal and rating services rendered by it fees ranging from JPY125,000 to approximately JPY250,000,000.\nMJKK and MSFJ also maintain policies and procedures to address Japanese regulatory requirements."
}