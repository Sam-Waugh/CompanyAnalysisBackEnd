{
    "headline": "Credit risk modeling of public firms: EDF9",
    "link": "https___www_moodys_com_web_en_us_insights_resource",
    "content": "QUANTITATIVE RESEARCH GROUP\nJUNE 2015\nMODELING Credit Risk Modeling of Public Firms: EDF9\nMETHODOLOGY\nAuthors Abstract\nPooya Nazeran\nDouglas Dwyer EDF9 — the 9th generation of the Moody’s Analytics Public Firm EDFTM (Expected Default\nFrequency) model — expands the frontiers of structural credit risk modeling. EDF metrics are\nAcknowledgements\nforward-looking probabilities of default, available on a daily basis for 35,000-plus corporate and\nWe are grateful for the advice and insights\nfinancial firms. The updated EDF9 model incorporates insights attained by evaluating the behavior\nprovided by Vera Arsova, Clara Bernard, Louis\nof the prior version, EDF8, over the course of the recent financial and sovereign debt crises. EDF9\nChapman, Ramkumar Chandramohan, Nan\nChen, Christopher Crossen, Houman Dehghan, also utilizes a larger dataset, given the global expansion of the equity markets, enhanced data\nMin Ding, Jian Du, James Edwards, Danielle quality, and improvements in computational performance. This paper explains the Public Firm EDF\nFerry, David Hamilton, Fangze Huang, Glenn model’s basic methodology, as implemented in the new EDF9 version. It also explains the\nLevine, Zaid Marji, Jacob Matsibekker, Mathew\nstructure and conceptual grounding of the core model and highlights new model features.\nMcDonald, David Munves, Paolo Persurich,\nAdditionally, we provide empirical details of the model’s calibration.\nCristina Pieretti, Tanya Roosta, Amrit Sandhir,\nSukie Sun, Zhao Sun, Sunny Wong, Pierre Xu,\nSherry Yang, Jing Zhang, Sue Zhang, and Yaran\nZhang.\nContact Us\nAmericas\n+1.212.553.1653\nclientservices@moodys.com\nEurope\n+44.20.7772.5454\nclientservices.emea@moodys.com\nAsia-Pacific (Excluding Japan)\n+85 2 3551 3077\nclientservices.asia@moodys.com\nJapan\n+81 3 5408 4100\nclientservices.japan@moodys.comQUANTITATIVE RESEARCH GROUP\nTable of Contents\n1. Introduction 3\n2. Theoretical Background of the Public Firm Model 4\n3. Practical Implementation of the VK / EDF Model 6\n3.1 Market Value of Assets 7\n3.1.1 Dividends Coupons and Interest Expense 8\n3.1.2 Convertible Securities 8\n3.1.3 Current and Long-term Liabilities 8\n3.1.4 Preferred Stock 8\n3.1.5 Implementation 8\n3.2 Default Point 9\n3.2.1 Financial Firms 9\n3.2.2 Off-Balance Sheet Items 10\n3.3 Asset Volatility 10\n3.3.1 Empirical Volatility 11\n3.3.2 Modeled Volatility 11\n3.3.3 Forward-Looking Asset Volatility 12\n3.3.3.1 Theory 12\n3.3.3.2 Practice 13\n4. Mapping Distance-to-Default to EDF Measures 15\n4.1 Concept 15\n4.2 Calibration 15\n4.3 Implementation 16\n4.4 Defining Default 17\n4.5 Financial Firms 17\n4.6 Upper Bound 18\n4.7 Performance in Different Portfolios 20\n5. Assessing Public Firm EDF Model Performance 23\n5.1 Rank-Ordering Power of Distance-to-Default 23\n5.1.1 Important Accuracy Ratio Caveats 25\n5.1.2 Importance of Accuracy Ratio Standard Error 26\n5.1.3 Accuracy Ratio at Different Horizons 27\n5.2 Temporal Characteristics of EDF Levels 27\n6. Conclusion 31\nAppendix A The Public Firm EDF Model within the Context of Moody’s Analytics Credit Risk Solutions 32\nAppendix B Conceptual Grounding of the Public Firm Model 33\nAppendix C Calibration Sample Size Cuts 38\nReferences 40\n2 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n1. Introduction\nMeasuring a firm’s probability of default (PD) is one of the\nWhat’s New in EDF9\ncentral problems of credit risk analysis. Moody’s Analytics’\nPublic Firm EDF (Expected Default Frequency) model has been While EDF9 uses the same conceptual framework as EDF8, we\nthe industry-leading PD model since its introduction in the make a number of important enhancements.\nearly 1990s. Since that time, the model has undergone\nWe have updated and improved DD-to-EDF measure\nconsiderable development, and it continues to evolve, while\nmapping. The mapping for non-financial firms now\nproviding unequalled global coverage of public firms on a\nincorporates international defaults from 1987 – 2014.\ndaily basis.\nFor the first time with the Public Firm model, we introduce a\nSince the release of the previous version, EDF8, the global\nfinancial firm-specific DD-to-EDF mapping that uses\neconomy experienced a financial crisis that expanded into\ninternational financial firm failures spanning 1987 – 2014. EDF\nwhat has been called the Great Recession.1 Europe dealt with\nvalues for financial firms represent the risk of either a default\nsovereign credit crises. Monetary policy took on an\nor a government bailout. The numerous financial firm failures\nunprecedented role in the broader economy. Considerations\nobserved during the last seven years makes such a mapping\nof quantitative easing, as well as bailouts, became important\nfeasible. Financial firm-specific mapping generates more\npricing factors for fixed-income securities. The term SIFI2 was\nstable EDF values over time for this sector. Consequently,\nintroduced, and new regulations were introduced around the\nEDF9 values are typically lower than EDF8 for the riskiest\nworld, affecting capital market structures and the roles both\nfinancial firms during a bad stage of the cycle, and,\nprivate and public institutions play. At the same time, the\nconversely, EDF9 values are typically higher than EDF8 values\nBRIC3 countries and other emerging markets continued to\nfor the safest financial firms during a good stage of the cycle.\nexpand, resulting in a large increase in the number of publicly\nWe also revisited the calculation of the financial firm default\ntraded firms. Subsequently, data feeds expanded coverage\npoint. Relative to EDF8, we employ a relatively simple and\noutside of North America.\nparsimonious calculation. This change makes the model more\nIn light of these events, we revisited our process of measuring transparent for financial firms.\nPD’s. The updated model and data used in EDF9 reflect new\nWe also made refinements to the volatility calculation. These\nlessons learned from the most recent credit cycle. An\nrefinements fine-tune a volatility measure that is now\nimportant revision expands the EDF9 dataset for financial firm\nimplemented consistently across the globe, and granularity is\nfailures, which improves our ability to predict defaults for\nnow country-level. Additionally, the volatility measure better\nthese firms. Financial firms typically present a different default\nreflects the volatility trends of the specific country and\ndynamic when compared to non-financial corporations. The\nindustry that a firm operates within. This volatility measure is\nincrease in the number of financial firm failures in our default\nsomewhat higher when volatility is low on a historical basis.\ndatabase enabled us to refine the Public Firm EDF model’s\ntreatment of financial firms in multiple ways. EDF9 also Finally, we produce EDF values back to 1963 using one\nbenefits from the global growth of exchanges. This expansion uniform algorithm.\nenables more granular modeling of certain risk-factors, which\ntailors the risk metric to the specific country where a firm\nresides.\nEDF9 retains the principal structure and conceptual grounding of the core model. The model remains an option-pricing based,\nstructural model. We continue to utilize Vasicek’s formulation of option contracts, as implemented in the original KMV model.\nEDF9 also continues to summarize all credit risk-related information into one metric, called Distance-to-Default (DD). We then\nmap the DD to the probability space to obtain the EDF credit metric.\nThis paper explains the recent updates and changes made to the model, the rationale for the changes, and their implications for\nthe one-year EDF measure.4\n1 We use the term “Great Recession” to refer to the period that began with a financial crisis in late 2007 and then spread, impacting non-financial firms, the\nunemployment rate, other macroeconomic variables, and sovereign credit risk. This recessionary period ended in mid-2009.\n2 Systematically Important Financial Institutions.\n3 Brazil, Russia, India, and China.\n4 Chen, et. al (2015) provides an overview of many aspects of the EDF9 framework. By focusing on the one-year EDF credit measure, this paper provides an in-\ndepth discussion of Section 4 in that overview paper.\n3 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nWe organize the paper as follows:\nSection 2 presents the theoretical background of the Public Firm EDF model and discusses its basic structure and components. For\nreaders new to structural modeling, Appendix B explores the model from a perspective more familiar to those with fundamental\nanalysis background.\nSection 3 details specific EDF9 model updates and changes, as well as practical implementations of the model.\nSection 4 discusses model changes pertaining to the calibration of the model’s DD-to-EDF transformation.\nSection 5 provides general measures of model performance.\nSection 6 summarizes and concludes.\nAppendix A describes the products, services, and models related to the Moody’s Analytics Public EDF model suite. These products\ninclude: CreditEdge®, RiskCalc™, GCorr™ and RiskFrontier™.\n2. Theoretical Background of the Public Firm Model\nThis section presents the Public Firm EDF model’s background and discusses its basic structure and components.\nWhile many readers are comfortable with the underlying theoretical framework of the KMV structural model, others may be new\nto it. Many authors provide useful descriptions of how the approach works using option-pricing theory. For in-depth overviews,\nplease refer to Crosbie and Bohn (2003), Ranson (2005), Caouette, et.al (2008), Bohn and Stein (2009), Duffie and Singleton\n(2012). For readers new to the model, Appendix B provides a more conceptual walk-through that describes the motivation behind\nthe framework by transforming an accounting-based measure of leverage into a heuristic approximation to the Distance-to-\nDefault concept.\nThe Public Firm EDF model belongs to the class of structural credit risk models, pioneered by Fischer Black, Robert Merton, and\nMyron Scholes. This model, originated by KMV,5 takes an option-pricing based approach to credit risk. Only when an option\ncontract expires in-the-money, does it receive a payoff. Naturally, the valuation reflects the probability of the contract expiring\nout-of-the-money. Due to limited liability laws, the market value of a publicly traded company’s equity is lower bounded at zero,\ngiving it call option-like characteristics. Hence, the default probability is embedded in the stock price. The stock price, however,\ncontains other information as well. This complexity makes extracting the PD an interesting problem. Option pricing research\nprovides a mathematical structure, within which, we can study default probabilities.\nStochastic calculus, in the context of Merton’s model, can be used to understand the link between the market value of assets and\nthe market value of equity. Let the market value of a firm’s underlying assets follow a stochastic process:\n( 1 )\nwhere 𝒅𝒅𝒅𝒅=𝝁𝝁𝒅𝒅𝒅𝒅 𝒅𝒅𝒅𝒅+𝝈𝝈𝒅𝒅𝒅𝒅 𝒅𝒅𝒅𝒅\nare the value of firm’s assets, and their change.\nare two parameters governing, respectively, the drift and risk of assets.\n𝒅𝒅,𝒅𝒅𝒅𝒅\nis the Wiener process\n𝜇𝜇𝐴𝐴,𝜎𝜎𝐴𝐴\nTheoretically, default occurs when the firm’s asset value falls to the default point level. The probability that asset values drop to\n𝑑𝑑𝑑𝑑\nsuch levels depends on the distribution of asset returns, which is, in part, characterized by asset volatility. We can formulate this by\npositing the following as the question of interest:\n( 2 )\nwhere D is the default point, and the subsc𝑷𝑷ri𝑷𝑷pt𝒅𝒅 t= in𝑷𝑷di𝑷𝑷ca[𝒅𝒅te𝒅𝒅s ≤tim𝑷𝑷e] in= th𝑷𝑷e𝑷𝑷 f[u𝒍𝒍𝒍𝒍tu(r𝒅𝒅e.𝒅𝒅 B)y≤ It𝒍𝒍o𝒍𝒍’s( l𝑷𝑷em)]ma, the equation describing the asset\nvalue process implies:\n( 3 )\n𝟏𝟏 𝟐𝟐\n𝒍𝒍𝒍𝒍(𝒅𝒅𝒅𝒅)=𝒍𝒍𝒍𝒍(𝒅𝒅𝟎𝟎)+�𝝁𝝁𝒅𝒅−𝟐𝟐𝝈𝝈𝒅𝒅�∙𝒅𝒅+𝝈𝝈𝒅𝒅 √𝒅𝒅∙𝒅𝒅\n5 KMV was acquired by Moody’s Corporation in 2002. KMV is currently part of Moody’s Analytics, a subsidiary of Moody’s Corporation.\n4 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nWhere w is the source of stochasticity, with a known distribution. In that case, the probability equation can be written as:\n( 4 )\n𝟏𝟏 𝟐𝟐\nwhich can then be simplified to: 𝑷𝑷𝑷𝑷𝒅𝒅 =𝑷𝑷𝑷𝑷�𝒍𝒍𝒍𝒍(𝒅𝒅𝟎𝟎)+�𝝁𝝁𝒅𝒅−𝟐𝟐𝝈𝝈𝒅𝒅�∙𝒅𝒅+𝝈𝝈𝒅𝒅 √𝒅𝒅∙𝒅𝒅≤𝒍𝒍𝒍𝒍(𝑷𝑷)�\n( 5 )\n𝒅𝒅𝟎𝟎 𝟏𝟏 𝟐𝟐\n𝒍𝒍𝒍𝒍�𝑷𝑷�+�𝝁𝝁𝒅𝒅−𝟐𝟐𝝈𝝈𝒅𝒅�∙𝒅𝒅\n𝑷𝑷𝑷𝑷𝒅𝒅 =𝑷𝑷𝑷𝑷� 𝝈𝝈𝒅𝒅√𝒅𝒅 ≤−𝒅𝒅�\nThe factor inside this formula is Distance-to-Default. In the finance literature, we find derivations for a heuristic version, presented\non the left-hand side of equation 6.6 Appendix B shows an alternative derivation of equation 6, from a balance sheet perspective.\n( 6 )\n𝒅𝒅\n𝒅𝒅−𝑷𝑷 𝒍𝒍𝒍𝒍�𝑷𝑷�\nIn order to compute DD, we must estimate and . Befo𝒅𝒅re∙𝝈𝝈 𝒅𝒅di≈ scus𝝈𝝈s𝒅𝒅ing our implementation of the estimation process, we discuss\nhow to estimate and using the Black-Scholes formula.\n𝐴𝐴0 𝜎𝜎𝐴𝐴\nAs a special case 𝐴𝐴of0 the M 𝜎𝜎e𝐴𝐴r ton model, it is possible to use the Black-Scholes formula to illustrate the process behind estimating\nasset value. In practice, we use the Vasicek-Kealhofer (VK) model to calculate EDF measures, and we discuss the particular\nimplications of that to asset value calculation later on in this paper.\nEquity is the present value of earnings, the residuals of cash flows, after all others obligations have been met. But equity is subject\nto limited liability. This relationship is analogous to a call option, which has a claim to the assets in excess of the strike price. In our\ncase, the strike price is the book value of liabilities.\nWe can exploit this characteristic of equity to asset value in a Black-Scholes context:\n( 7 )\n−𝑷𝑷𝒓𝒓\nwhere 𝑬𝑬=𝒅𝒅 Ф(𝒅𝒅𝟏𝟏)−𝒆𝒆 𝑿𝑿 Ф(𝒅𝒅𝟐𝟐)\nis the equity value.\n𝐸𝐸\n𝐴𝐴0 1 2\n𝑙𝑙𝑙𝑙�𝐷𝐷�+�𝑟𝑟+2𝜎𝜎𝐴𝐴�∙𝑇𝑇\n𝑑𝑑1 = 𝜎𝜎𝐴𝐴√𝑇𝑇\n𝐴𝐴0 1 2\n𝑙𝑙𝑙𝑙�𝐷𝐷�+�𝑟𝑟−2𝜎𝜎𝐴𝐴�∙𝑇𝑇\n𝑑𝑑\n2is =the risk- 𝜎𝜎f 𝐴𝐴re √e\n𝑇𝑇\ninterest rate\nis the cumulative standard normal distribution function.\n𝑟𝑟\nWhilФe in an option-pricing context is taken as given and is calculated, for our purposes, we can use the observed to estimate\nthe market value of assets.\n𝐴𝐴 𝐸𝐸 𝐸𝐸\n𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴 =𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶 𝑂𝑂𝑂𝑂𝐴𝐴𝑂𝑂𝑂𝑂𝑂𝑂+𝑆𝑆𝐴𝐴𝑟𝑟𝑂𝑂𝑆𝑆𝐴𝐴 𝑃𝑃𝑟𝑟𝑂𝑂𝑃𝑃𝐴𝐴−𝑃𝑃𝑃𝑃𝐴𝐴 𝑂𝑂𝑂𝑂𝐴𝐴𝑂𝑂𝑂𝑂𝑂𝑂\nWhile this estimation of asset valu𝐴𝐴e 𝐴𝐴re𝐴𝐴f𝐴𝐴le𝐴𝐴c=ts 𝐸𝐸th𝐸𝐸e𝑃𝑃 d𝑂𝑂e𝐴𝐴𝐸𝐸fau+lt𝐿𝐿 r𝑂𝑂is𝐶𝐶k𝑎𝑎 p𝑂𝑂𝐶𝐶r𝑂𝑂e𝐴𝐴m𝑂𝑂𝐴𝐴iu𝐴𝐴m−,7𝐷𝐷 e𝐴𝐴q𝐷𝐷ua𝐶𝐶t𝑃𝑃io𝐶𝐶𝐴𝐴n 𝑅𝑅7 𝑂𝑂i𝐴𝐴s 𝑆𝑆n o𝑃𝑃t𝑟𝑟 p𝐴𝐴r𝑃𝑃ac𝑂𝑂t𝑃𝑃ic𝑃𝑃al as, for instance, one cannot\nreflect the value of preferred stock in said premium, different maturities of liabilities cannot be specified, and equity cannot be\ntreated as a perpetual option without an expiration date. We discuss these restrictions and our solution for them in Section 3.\nTo estimate , we need to understand how changes in equity value are related to changes in asset value. As the residual of asset\nvalue after obligations are met, equity value’s dependence on changes in asset value can be described with partial derivatives.\n𝜎𝜎𝐴𝐴\n𝝏𝝏𝑬𝑬\n𝒅𝒅𝑬𝑬=𝝏𝝏𝒅𝒅∙𝒅𝒅𝒅𝒅 ( 8 )\n6 For instance, refer to Crosbie and Bohn (2003).\n7 For the purpose of this discussion, the default risk premium is not in yield space, but rather in price space. In other words, it can be thought of as the price\ndifferential between the market value of a default-risky bond and the market value of a bond with identical cash flows, but without default-risk.\n5 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n𝒅𝒅𝑬𝑬 𝝏𝝏𝑬𝑬 𝒅𝒅 𝒅𝒅𝒅𝒅\n𝑬𝑬 =𝝏𝝏𝒅𝒅∙𝑬𝑬∙ 𝒅𝒅 ( 9 )\n𝜕𝜕𝐸𝐸 𝐴𝐴\nThere are two key terms governing the relation between a 𝑟𝑟s𝐸𝐸se =t retur ∙ns a ∙n 𝑟𝑟𝐴𝐴d equity returns, notably and . To illustrate the role of\nthe first term, consider an institution with $1B in assets and zer𝜕𝜕 o 𝐴𝐴 liab𝐸𝐸 ilities. Each change in asset va𝐴𝐴lue pr𝜕𝜕o𝐸𝐸pagates to equity\nvaluation dollar-for-dollar. Hence, the company’s assets and equity will have the same volatility. In𝐸𝐸 the c𝜕𝜕a𝐴𝐴se of a firm with $1B in\nassets but $500MM in liabilities, a $10MM change in assets changes asset values by 1%, while the effect of a $10MM change in\nequity is 2%.\nHowever, that change is not exactly 2% because of . Take a bank for example, with $1B in assets and $900MM in liabilities.\n𝜕𝜕𝐸𝐸\nWithout limited liability, would be one, and a 1% change in assets results in an 11% change in equity. But, given limited liability,\n𝜕𝜕𝐴𝐴\nas the value of assets bec𝜕𝜕o𝐸𝐸mes closer to the value of total liabilities (strike price), the derivative becomes smaller, reflecting\nincreased default risk. Con𝜕𝜕s𝐴𝐴equently, the $10MM is distributed between both changes in the market value of liabilities and changes\nin equity valuation, with a change in equity of less than 11%.\nThe reflects the effect of the optionality in equity and is what option investors call delta. The delta parameter appears in the\nappli𝜕𝜕c𝐸𝐸ation of Ito’s lemma, which provides a more formal derivation of the relation between asset volatility and equity volatility.\nWe e𝜕𝜕n𝐴𝐴d this section with the formal derivation.\nSince the value of equity is determined, in part, based on the value of assets, we can describe it in a simple notation as\nBy Ito’s lemma, we arrive at:\n𝐸𝐸 =𝐷𝐷(𝐴𝐴)\n( 10 )\n𝟐𝟐\n𝝏𝝏𝑬𝑬 𝝏𝝏𝑬𝑬 𝟏𝟏𝝏𝝏 𝑬𝑬 𝟐𝟐 𝟐𝟐 𝝏𝝏𝑬𝑬\n𝒅𝒅𝑬𝑬= �𝝏𝝏𝒅𝒅 +𝝏𝝏𝒅𝒅𝝁𝝁𝒅𝒅𝒅𝒅+𝟐𝟐𝝏𝝏𝒅𝒅𝟐𝟐𝝈𝝈𝒅𝒅 𝒅𝒅 �𝒅𝒅𝒅𝒅+𝝏𝝏𝒅𝒅𝝈𝝈𝒅𝒅𝒅𝒅 𝒅𝒅𝒅𝒅\nOn the other hand, itself is a stochastic process and can be described as:\n( 11 )\n𝑑𝑑𝐸𝐸\nMatching the second term of each equation, we arr𝒅𝒅iv𝑬𝑬e a=t: 𝝁𝝁𝑬𝑬,𝒅𝒅𝑬𝑬 𝒅𝒅𝒅𝒅+𝝈𝝈𝑬𝑬,𝒅𝒅𝑬𝑬 𝒅𝒅𝒅𝒅\n( 12 )\n𝝏𝝏𝑬𝑬 𝒅𝒅\nThis formula implies that equity volatility changes as the 𝝈𝝈le𝑬𝑬 v,𝒅𝒅 er=ag𝝏𝝏e𝒅𝒅 o∙f 𝑬𝑬a ∙fi𝝈𝝈rm𝒅𝒅 changes. Therefore, one cannot use it to determine\nasset volatility from equity volatility if equity volatility is measured as the standard deviation of equity returns over a window\nwhere leverage changes.\n3. Practical Implementation of the VK / EDF Model\nThis section covers implementation considerations of the three primary drivers of the model: asset value, default point, and asset\nvolatility. Figure 1 provides a visual representation of the relationship between these components of the model and their dependencies.\nWe also highlight the significant improvements found in EDF9.\nThe VK model, the foundation for the Public Firm EDF model and EDF9, extends on the Merton model in a number of ways. The\nextensions are intended to make the Merton model more useful in practice. The extensions allow the Merton model to be applied\nto firms with different types of capital structures. The VK model includes both short-term and long-term debt. Further, it allows for\nconvertible securities and cash leakages. Finally, it incorporates a concept of preferred stock.\nIn EDF9, we make the following changes: For all firms, an adjustment is made to the default point to reflect the cost of capital. For\nfinancial firms, we simplify the specification of the default point. Asset volatility is the combination of empirical volatility and\nmodeled volatility. For empirical volatility, we now measure it consistently throughout the world using a three-year window of\n6 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nweekly returns. For modeled volatility, we incorporate higher granularity with respect to geography and industry. Last, a new\ncomponent has been introduced into the asset volatility calculation, which makes it more forward-looking.\nFigure 1 Public EDF Model and Drivers\n3.1 Market Value of Assets\nIn the VK model, the market value of a firm’s assets equals the sum of the market values of common stock, convertible securities,\nshort-term debt, and long-term debt. We begin by describing the concept of asset value and then discuss each component in turn.\nThe concept that balance sheets’ balance states is that the value of assets equals the value of liabilities and equity combined.\nWhile the balance sheet reflects their book valuations, the equality continues to hold for market valuations. With the market value\nof publicly traded equity, this implies we can calculate the market value of assets if we know the market value of liabilities.\nThe book value of debt (money a firm has borrowed from a lender) is typically the discounted value of the remaining future\npayments, discounted at whatever interest rate the firm and the lender agreed to when the debt was originated. As both the risk-\nfree rate and the firm’s credit risk change over time, the book value of a debt typically differs from its market value — how much a\nthird party would pay the firm’s creditor for the debt. Had the firm’s liabilities been risk-free, the market value of liabilities could\nhave been calculated by discounting the future payments with a risk-free interest rate. In practice, because of default risk, the\nmarket value is less.8\n( 13 )\nAs a firm’s li𝑴𝑴ab𝑴𝑴ili𝑷𝑷ti𝑴𝑴es𝒆𝒆 𝒅𝒅a r𝑽𝑽e 𝑴𝑴co𝒍𝒍𝑽𝑽m𝒆𝒆p l𝒐𝒐e𝒐𝒐x, 𝑳𝑳it𝑳𝑳 i𝑴𝑴s 𝑳𝑳ty𝑳𝑳p𝒍𝒍𝑳𝑳ic𝒅𝒅a𝑳𝑳l𝒆𝒆ly𝑳𝑳 n=ot 𝑹𝑹po𝑳𝑳𝑳𝑳ss𝑴𝑴ib𝒍𝒍l𝒆𝒆e𝑳𝑳 t𝑳𝑳o 𝑽𝑽di𝑴𝑴re𝒍𝒍c𝑽𝑽t𝒆𝒆ly 𝒐𝒐o𝒐𝒐b s𝑳𝑳e𝑳𝑳rv𝑴𝑴e𝑳𝑳 t𝑳𝑳h𝒍𝒍e𝑳𝑳𝒅𝒅 m𝑳𝑳𝒆𝒆a𝑳𝑳rk−et 𝑷𝑷va𝒆𝒆l𝒐𝒐ue𝑴𝑴 𝑽𝑽of𝒍𝒍 a𝒅𝒅 𝑹𝑹fir𝑳𝑳m𝑳𝑳𝑴𝑴’s 𝑷𝑷lia𝑷𝑷b𝒆𝒆il𝑷𝑷itie𝑳𝑳𝑽𝑽s. 𝑷𝑷Oldrich\nVasicek developed a model in the 1980s that estimates both the market value of assets and the market value of liabilities from the\nmarket value of equity. The model takes asset value, asset volatility, the risk-free rate, as well as a few balance sheet and income\nstatement items and returns the difference between the risk-free and risky value of the debt, namely the default risk premium.\nThe standard Merton model assumes two types of claims to the cash flow generated by a firm — debt with no coupons and equity\nwith no dividends. This model posits that the underlying assets can be represented by a geometric Brownian motion process that is\nparameterized by volatility and a drift term. The debt is a one-time payment at a specified point in time. In this context, the actual\nsolution is the Black-Scholes option-pricing formula.\nThe structural model that forms the foundation for the Public Firm EDF model is the Vasicek-Kealhofer (VK) model. The VK\nframework assumes five types of claims on the firm’s cash flows: short-term liabilities, long-term liabilities, convertible securities,\npreferred stock, and common stock. Incorporating these different types of contingent claims into the model changes both the\nasset value formula and the boundary conditions.\n8 One can think of the default risk premium as the present value of a CDS contract. Indeed, it is for this risk that credit default swap (CDS) contracts exist and\ntrade. If we had the present value of a CDS contract, in other words, the upfront fee demanded on a hypothetical zero-coupon CDS contract, we could\ncalculate market value of liabilities. For most publicly traded firms, however, there is no CDS contract, and, where there is one, it may not be liquid, and,\nwhere it is liquid, it may only reflect the risk premium on a subclass of the firm’s liabilities.\n7 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n3.1.1 Dividends Coupons and Interest Expense\nCash leakages in the forms of dividends on stock, coupons on bonds, and interest expense on loans impact both default\nprobabilities and debt value. For example, consider two firms with identical assets and debt, but one pays a larger dividend. The\nfirm paying the larger dividend has a higher default probability, even though the dividend may be cut in the event of distress; any\nhigher dividend payments made until distress became apparent would reduce the cash flow available to service debt. The VK\nmodel incorporates cash outflows directly into the different types of claims on a firm’s assets.\n3.1.2 Convertible Securities\nCompanies may issue securities that can be converted into equity at a specified conversion rate. Such securities are often preferred\nstock, but bonds can be convertible as well. By issuing such securities, the firm is effectively selling a portion of the upside return\nthat otherwise belongs to the common stock holders. Consider two firms: A and B. Both have the same assets and debt. Company\nB has a convertible security outstanding, so the fully-diluted shares outstanding exceeds the common shares outstanding. Under\nthis scenario, Company B has a lower market value of equity than Company A, even though the default probability is the same.\nHolders of common stock in company B sell a portion of the upside return to the holders of the convertible security. This\ndifference becomes reflected in one of the boundary conditions for the VK model — that, as the asset value of the firm becomes\narbitrarily large, the derivative of equity value, with respect to asset value, becomes equal to the ratio of the shares outstanding,\ndivided by the number of fully diluted shares outstanding. The dilution effect of convertible securities reduces the sensitivity of the\nvalue of equity to the value of assets. If this dilution effect is ignored, when observing the equity value of a company that has a\nlarge number of convertible securities, one underestimates the market value of assets and overstates the probability of default.\n3.1.3 Current and Long-term Liabilities\nIn structural models that use an absorbing default barrier, two approaches have been taken to define the barrier. The default event\ncan be driven by creditors forcing the company into default when the asset value falls below the barrier. Alternatively, if there are\nno protective covenants, the company can choose to default when the value of equity falls to zero — if the value of assets falls\nbelow a certain threshold, then the equity holders choose to stop making payments on the debt and, thereby, turn over the firm’s\nassets to debt holders.9 In the VK model, the barrier is exogenous, in the sense, that creditors put the debt back to the firm as soon\nas the value of assets hits the value of the default point. This barrier forms the second boundary condition of the model — the\nvalue of equity equals zero when the value of the firm’s assets equals the default point.\n3.1.4 Preferred Stock\nPreferred stock has both equity and debt characteristics, and the model takes both these aspects into consideration. The VK model\ncan incorporate various types of preferred stock, including tradable preferred stock and convertible preferred stock.\n3.1.5 Implementation\nVasicek’s formula poses two implementation challenges: its dependence on asset value and its dependence on asset volatility.\nWe require the default risk premium to estimate the market value of liabilities in order to subsequently calculate the market value\nof assets. On the other hand, we need the market value of assets for the default risk premium calculation. We resolve this issue\nwith the put-call parity equation, directly deduced from the definition of option contracts. In our context, it implies\n( 14 )\nExposure to d𝒅𝒅e𝑳𝑳fa𝑳𝑳u𝒆𝒆l𝒅𝒅t 𝑽𝑽ris𝑴𝑴k𝒍𝒍 i𝑽𝑽s 𝒆𝒆sim=il𝑬𝑬ar𝑬𝑬 t𝑽𝑽o 𝑳𝑳s𝒅𝒅h𝑬𝑬o r𝑽𝑽ti𝑴𝑴ng𝒍𝒍𝑽𝑽 a𝒆𝒆 p+ut 𝑹𝑹op𝑳𝑳𝑳𝑳ti𝑴𝑴o𝒍𝒍n𝒆𝒆, 𝑳𝑳as𝑳𝑳 i𝑽𝑽t m𝑴𝑴𝒍𝒍a𝑽𝑽ke𝒆𝒆s 𝒐𝒐 t𝒐𝒐he 𝑳𝑳 c𝑳𝑳r𝑴𝑴e𝑳𝑳di𝑳𝑳t𝒍𝒍o𝑳𝑳r𝒅𝒅 s𝑳𝑳u𝒆𝒆b𝑳𝑳je−ct𝑷𝑷 to𝒆𝒆 𝒐𝒐th𝑴𝑴e𝑽𝑽 r𝒍𝒍is𝒅𝒅k 𝑹𝑹 o𝑳𝑳f𝑳𝑳 a𝑴𝑴ss 𝑷𝑷et𝑷𝑷s𝒆𝒆 d𝑷𝑷ro𝑳𝑳p𝑽𝑽p𝑷𝑷ing below the\ndefault point. By solving this equation, we obtain estimations for asset value, put option, and hedge ratio.\nAsset volatility is also a necessary input, which we address in later sections. Before proceeding, it is important to clarify that we do\nnot change the put option equation in EDF9. Nonetheless, as inputs such as asset volatility have typically changed, the resulting\nasset value for a specific name at a specific point in time is typically different when compared to EDF8.\n9 For early implementations of so-called exogenous and endogenous default barriers, see Black, Cox (1975) and Leland (1994), respectively.\n8 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n3.2 Default Point\nWhat’s New in EDF9: For all firms, we introduce a cost-of-capital adjustment to the default point. Furthermore, we reformulate the\ndefault point for financial firms.\nThe long-standing practice of defining the default point has been “current liability + ½ long term liability.” This formula originates\nfrom KMV research and has been employed in the academic literature. As part of the EDF9 research, we reevaluated the formula\nagainst many alternative possibilities. We found that the other approaches were not consistently better than the long-standing\npractice for non-financial firms. For financial-firms, however, we make a change to the default point calculation, which we discuss\nin the next section.\nLooking at model behavior in different interest rate environments, we also add a cost-of-capital adjustment to the default point,\nfor all business types. In a high interest rate environment, a firm’s business partners are less willing to rollover credit and allow\naccumulation of unpaid bills, when compared to a low interest rate environment. Since, in a high interest rate economy, working\ncapital depletes faster and access to credit becomes expensive, all else being equal, the default rate is expected to be higher.\nControlling for all other aspects of credit risk, we indeed find that an unadjusted default point underestimates credit risk during the\n1980s and 1990s and overestimates during the more recent low-rate periods. Adjusting the default point by the cost-of-capital,\nusing 1+r, we find improvements to the EDF measure across the different interest rate environments. As rates have been fairly low\nduring 2014 and 2015, to the extent that they increase in the future, all else being equal, the model should estimate higher EDF\nmeasures.\n3.2.1 Financial Firms\nEstimating the default point as current liabilities plus one-half long term liabilities for financials is problematic, as financial firms\ntypically do not report current liabilities as a separate line item on their balance sheets.\nWhile a financial firm’s balance sheet lists long-term debt, identification of the term structure of the remaining balance sheet is\nnot so straightforward. For the Public EDF model, we had developed a method for estimating the long-term component of the\nremaining liabilities, using a firm’s size, as well as sector-level information. However, in EDF8 and earlier versions of the model, we\nalso faced another challenge — scarcity of default events among publicly traded financial firms at the time. This issue further\ncomplicated the modeling of a default point for such firms.\nFollowing the recent financial crisis, we possessed sizeable financial firm default data, which helps us understand their credit risk\nand default dynamics much better.\nHaving confirmed that the long-term liabilities of a non-financial corporate imposes half the burden of current liabilities, we\nhypothesized that long-term debt also plays a different role in a financial firm’s default point. We further separated deposits from\nthe rest of liabilities. In other words, we separated total liabilities of a financial firm into three components: long-term debt,\ndeposits, and everything else. In searching for differential impacts of different liability types, we empirically evaluated the data. We\nassessed the performance of the model for a variety of different default point definitions. We were unable to find a consistent and\nstatistically meaningful difference between these three components of total liabilities.\nOur findings can be attributed to the sophistication of the instruments on a financial firm’s balance sheet. The same sophistication\nthat makes it difficult for most accountants to identify and separate current liabilities from long-term liabilities could affect the\ninformativeness of the balance sheet. Furthermore, relative to non-financial corporates, financial firms can restructure their\nliabilities and change their tenor more flexibly. Naturally, all these possibilities comprise to make a financial balance sheet more\nopaque and its credit risk harder to measure.\nBased on our empirical findings, we set the default point as a percentage of total adjusted liabilities. We calibrate that percentage\nas 75%. The mentioned adjustment to total liabilities excludes minority interest and deferred tax, as they are not sources of credit\nrisk.\nA side benefit of this default point definition is more stable EDF measures for financials, relative to EDF8. In EDF8, the financial\nfirm default point depended on long-term debt, but on occasions, this value tended to vary dramatically between quarterly and\nannual statements.10 Subsequently, this variation introduced spurious changes in EDF8’s default point for financial firms, but does\nnot have any effect on EDF9’s default point.\n10 For an explanation on the role of variation of debt value on default point, refer to Knowledge Base FAQ 388 (2006).\n9 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n3.2.2 Off-Balance Sheet Items\nThe default point reflects the current and total liabilities of the balance sheet. A common concern is the impact of off-balance\nsheet items on the EDF measure. However, EDF measures’ sensitivity to off-balance sheet items is low, as the model compensates\nin its estimation of volatility.\nFor a firm with off-balance sheet items that are a source of credit risk, total liabilities is underreported. Subsequently, the asset\nvalue and the default point are understated. Take, for example, Bank B with equity valued at $65B,11 and $1T12 in total liabilities.\nWe estimate asset volatility at approximately 3% and asset value of $1005B. The $5B difference between the asset value and the\ntotal liabilities value tells us the estimated default risk premium equals $60B.\nLet us assume 10% of the liabilities are off-balance sheet and are not reflected in the $1T value. This means we underestimate the\ndefault point by about 10%, and, instead of $750B,13 it should be $825B. On the one hand, by the balance sheet principle, the\nasset value should be $75B more. On the other hand, this leverage increase raises the default risk premium from $60B to about\n$67B, as the higher-leverage means higher default risk. All in all, asset value increases by approximately 9%, while the default\npoint increases by about 10%. Our measure of leverage, asset value divided by default point, therefore, decreases by 1%, reducing\nDD by about 1%.\nBut this result affects our estimate of asset risk as well. If true total liabilities is $1.1T and true leverage 1% different, that means we\nde-levered equity returns with a ratio off by1%. Now, if we recalculate asset volatility with these corrected leverage ratios (further\ndiscussed in Section 7), instead of 3%, we find asset volatility is about 2.97%.\nSince asset value / default point is the primary driver of the DD’s numerator, and in the denominator it is asset volatility, the 1%\nreduction in the numerator is offset by the 1% reduction in the denominator, keeping the ratio by-and-large the same. We\nconsistently observe that these forces offset one another in a way that the model produces default probabilities that reflect the\ncredit risk of the obligor, as if all sources of risk had been reported on the balance sheet, and so long as they do not constitute a\nsubstantial portion of the liabilities.\nAll-in-all, as long as the market appreciates the existence of off-balance sheet items and reflects them in levering-up asset returns\nto equity returns, the model reflects their risk in its calculated EDF measure via the interaction of asset volatility and leverage. This\noffsetting effect demonstrates the important role played by the asset volatility estimation process.\n3.3 Asset Volatility\nAsset volatility serves two purposes in the model: one is in constructing the DD, and the other is in calculating the put option.\nMeasuring asset volatility, however, introduces multiple challenges. Unlike market capitalization, neither equity volatility nor asset\nvolatility is observable. These statistics can only be calculated over a window of returns, which subsequently introduces two\nchallenges: one emerges for new firms, as sufficient history is not available, and the other in the backward-looking characteristic of\nsuch a measure.\nWe measure the volatility of assets over a three-year window, using data at weekly frequency from 156 observations. In addition\nto empirically measuring asset volatility, we model it as well, to account for new firms where sufficient history is not available. For\neach firm, modeled volatility is the asset volatility of the typical firm with similar characteristics. We find three characteristics\ninformative of asset risk: size, location, and business type. By taking a weighted-average of empirical volatility and modeled\nvolatility, we compensate for sampling variability of the limited history of asset returns for any one firm.14\nThe Public EDF model forecasts the default probability over the next year, and hence, requires the asset volatility over the next\nyear, which is not available. Even with a full window of observations, the current asset volatility is not observable either, but we\nhave asset volatility during the past three years. The modeled volatility is calibrated to empirical volatility and, hence, does not\nchange its temporal features. Having observed the cyclical behavior of aggregate asset risk, at both the country-level and industry-\nlevel, we adjust the estimated asset volatility to become more prudent for the future. In the next few sections, we provide more\ndetails on empirical and modeled volatility, as well as the forward-looking adjustment.\n11 Sixty-five billion dollars\n12 One trillion dollars\n13 As mentioned in the previous section, the default point is 75% of adjusted total liabilities. For the purpose of this example, we assume deferred tax and\nminority interest are zero; so total adjusted liabilities is the same as total liabilities.\n14 For the intellectual origins of combining empirical and modeled asset volatility, see Vasicek (1973).\n10 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n3.3.1 Empirical Volatility\nWhat’s New in EDF9: We compute empirical volatility using a three-year window of weekly returns globally. EDF8, in contrast, used a\nfive-year window of monthly returns for some regions.\nThe process of empirically calculating asset volatility begins with estimating asset returns as de-levered equity returns. We then\nuse asset returns during the three most recent years for the estimation.15 In this section, we explain how we estimate asset returns,\nhow we deal with illiquidity, and how corporate events affect estimation.\nThe market value of assets equals the sum of the market value of equities plus the market value of liabilities. In order to compute\nasset returns, we must take into account how changes in the price of equity and the price of liabilities impact the market value of\nassets. After controlling for shares outstanding, as the stock price increases, the market value of assets increases. As interest rates\nincrease, the market value of liabilities declines, with the impact increasing in the tenor of the debt. Returns on long-term debt are\nestimated to a first-order approximation using the concept of Macaulay duration. We then compute asset returns as the sum of\nde-levered equity returns and the returns on long-term debt multiplied by the ratio of the long-term debt to asset value.\nConsistent with earlier versions of the Public EDF model, we apply an iterative process. The process begins with a guess for asset\nvolatility and subsequent calculation of asset value and hedge ratio. Hedge ratio is a byproduct of the asset value calculation\nprocess. Having calculated a time series of asset returns, we use it to update our asset volatility estimation. If the resulting\nvolatility has converged to the starting volatility, we consider the asset return final, otherwise, we iterate, taking this new volatility\nas the starting one.\nThe iterative approach is superior to “solving for two equations and two unknowns” found in some academic and commercial\nimplementations of structural models. Since equity volatility cannot be measured instantaneously and depends on a window,\nimplicit in de-levering equity volatility is the assumption that the leverage ratio, as well as hedge ratio, have been constant\nthroughout the window. As equity volatility changes with the market capitalization of the firm, this assumption is not valid in\npractice\nIf a firm’s stock is not liquid enough to have weekly returns, during the period of its illiquidity, the model resorts to using data at\nthe monthly frequency. To compensate for sampling variability resulting from fewer observations, we expand the three-year\nwindow. For the extreme case where a firm only has monthly returns available, we use a five year window.\nMajor corporate events such as mergers and acquisitions introduce another challenge. If such activity is about to occur or has even\nhappened but is not yet reflected in the new financial statements, the model is not aware of them, whereas, the market\nparticipants take the new capital structure into consideration when deciding to buy or sell at the prevailing price. Consequently,\nmarket prices and equity returns reflect such information. When the market knows the current financial statements are outdated,\nour de-levering process results in asset returns too volatile when total liabilities is too small (e.g., when there is M&A activity) and\nasset returns that understate volatility when total liabilities is too large (e.g., in the case of a spin-off). To account for this issue, the\nmodel has an event-adjustment mechanism that retroactively adjusts the asset returns of the event period in order to correctly\nestimate asset volatility. While still somewhat relevant, pre-event asset returns are not as relevant to post-event asset risk. So we\nlower the weight on pre-event asset returns. When empirically calculating volatility, we use the magnitude of the event to\ndetermine the weight on pre-event observations.\nTo further improve our asset volatility estimation, the model has a mechanism for identifying and winsorising outliers. Outlying\nasset returns can exist for a variety of reasons, but are not helpful in the estimation of asset risk, particularly given the model’s\nneed for next year’s risk. Such winsorising of outliers reduces spurious changes in volatility and, hence, EDF measures.\n3.3.2 Modeled Volatility\nWhat’s New in EDF9: We increase the modeling granularity with respect to business location and business type.\nIn general, modeled volatility is used to compensate for sampling error. A new firm does not have any equity returns for empirical\nmeasurement. Hence, the model relies 100% on modeled volatility. Over time, as more and more observations become available,\nthe model continuously shifts to place more weight on empirical volatility. At the extreme, where 156 observations are available,\nthe role of modeled volatility reduces to about 20%, but never 0%. Just as a Bayesian-prior is used to improve the estimation of a\nstatistic, even for firms with a full set of 156 observations, the model places some weight on modeled volatility. After all, even a\nsample of 156 observations contains sampling errors.\n15 EDF8 used three years of weekly returns to measure asset volatility in North America and Japan and five years of monthly returns elsewhere. This method\nwas, in part, due to the differences in the quality of equity returns available in different parts of the world, historically. For more information, please refer to\nKnowledge Base FAQ438 (2009).\n11 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nModeled volatility is composed of three additive components, as we find three factors effective in explaining asset volatility: size,\nlocation, and business type.\nAs larger firms possess more diversified assets, they tend to have lower overall asset risk. Looking at a variety of subsets, we find\nthat book value of assets, as well as sales, are two good indicators of size, but their relative importance in determining asset\nvolatility varies across industries. For each industry and over a large panel of data, spanning multiple decades, we calibrate the\nnon-linear relationship between asset volatility and firm size.\nEach month, after calculating empirical volatility using the subset where at least approximately two-years of equity returns are\navailable, we subtract the size-implied asset volatility from empirical volatility and cross-sectionally regress the residuals on\ncountry dummies and industry weights. Over time, the coefficients of these monthly regressions can be used to construct time\nseries that capture the systematic asset risk for each country-industry pair. One can think of these as volatility fixed-effects.\nAfter calculating the volatility fixed-effects and before calculating modeled volatility, we must account for small sample issues in\nspecific countries. While, as of now, all 68 country groups are sufficiently populated, most have had periods of sparse data at some\npoint during the past five decades. In such cases, we apply a Bayesian adjustment. We use five regions, and, for any country with\nless than 35 observations, after identifying its region and the fixed-effects of all countries in that region with more than 35\nobservations, we take the average of those fixed-effects as a Bayesian-prior and adjust the country’s fixed-effect accordingly. For\ncountries where no firms with at least two years of equity returns are available, the region level average fixed-effect is used until\nsuch firms become available.\nAs the description above shows, we calculate modeled volatility using two steps. We use a regression that estimates the country\nand industry fixed-effects after accounting for the size effect. The second step captures the systematic asset risk, which is cyclical.\nBy cross-sectionally running the regression and updating the fixed-effects on a monthly basis, we can measure the state of\nsystematic asset risk.\nModeled volatility does serve another purpose as well — facilitating the forward-looking adjustment. We elaborate on this point in\nthe next section.\n3.3.3 Forward-Looking Asset Volatility\nWhat’s New in EDF9: The forward-looking asset volatility adjustment is a new enhancement.\nOne of the completely new features introduced in EDF9 is forward-looking volatility. When aggregate asset risk in a region or\nindustry has been far above or below its long-run level, we find it to mean-revert later. As the DD requires future asset risk, due to\nthe backward-looking nature of any direct measure of asset volatility, we develop a forward-looking adjustment that results in a\nmore accurate, yet stable, measure of credit risk. We model the necessary adjustment by looking at the gap between short-run\nand long-run measures of asset risk within a country and industry.\nThe rest of this section provides theoretical justifications and then proceeds with implementation details.\n3.3.3.1 Theory\nIn its stylized form, we can split an asset return into systematic and idiosyncratic components.\n( 15 )\nOf the subscripts, f = “firm,” s “systematic,” i “idiosyncra𝑷𝑷t𝒐𝒐ic,𝒅𝒅,”= an𝜷𝜷d ∙t𝑷𝑷 “𝑳𝑳t,i𝒅𝒅m+e.𝑷𝑷” 𝑳𝑳T,𝒅𝒅he coefficient can be thought of in terms of a CAPM\n, as it captures the sensitivity of the firm’s returns to those of the market. Equation 16 implies a relationship among the standard-\ndeviation of the different components: 𝛽𝛽\n𝛽𝛽\n( 16 )\n𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐\nAs there is time-variation of asset risk, we introduce a\nti𝝈𝝈m𝒐𝒐\ne\n=sub𝜷𝜷scr∙ip𝝈𝝈t𝑳𝑳\n:\n+𝝈𝝈𝑳𝑳\n( 17 )\n𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐\nWe model the firm’s idiosyncratic component as time 𝝈𝝈in𝒐𝒐 v,𝒅𝒅 ar=ian𝜷𝜷t, w∙h𝝈𝝈i𝑳𝑳 le,𝒅𝒅 t+he𝝈𝝈 s𝑳𝑳 y,𝒅𝒅 stematic component is counter-cyclical, with mean-\nreverting tendencies.\n12 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nIn practice, our measurement of at time t is based on the most recent three years of data, whereas, for modeling purposes, we\nare interested in asset risk in the fu2ture. Let us begin by assuming the existence of a long-run asset risk level for the asset return\nand its components at a timeτin𝜎𝜎 𝑓𝑓 t, h𝑡𝑡 e future.\n( 18 )\n𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐\nWhere the expectation is taken over τ(ti𝝈𝝈m𝒐𝒐e,𝑳𝑳)𝑹𝑹. F=or 𝑬𝑬sh�𝝈𝝈or𝒐𝒐t,e𝒅𝒅+r 𝝉𝝉n�o=tat𝜷𝜷ion∙, 𝑬𝑬w�e𝝈𝝈 c𝑳𝑳 a,𝒅𝒅 n+ 𝝉𝝉 w�ri+te𝑬𝑬: �𝝈𝝈𝑳𝑳,𝒅𝒅+𝝉𝝉�\n( 19 )\n𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐\nIf we assume that , we can subtract equa𝝈𝝈t𝒐𝒐 io,𝑳𝑳 n𝑹𝑹 1=7 f𝜷𝜷rom∙ 𝝈𝝈eq𝑳𝑳, u𝑳𝑳𝑹𝑹 at+ion𝝈𝝈 1𝑳𝑳, 9𝑳𝑳 𝑹𝑹 and obtain:\n2 2\n𝜎𝜎𝑖𝑖,𝐿𝐿𝐿𝐿 =𝜎𝜎𝑖𝑖,𝑡𝑡 ( 20 )\n𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐 𝟐𝟐\nThe relationship above shows that when curren𝝈𝝈t 𝒐𝒐 le,𝑳𝑳 v𝑹𝑹 el=s o𝝈𝝈f 𝒐𝒐 s, y𝒅𝒅 s−te𝜷𝜷mat∙ic𝝈𝝈 r𝑳𝑳 i,𝒅𝒅 sk+ di𝜷𝜷ver∙g𝝈𝝈e 𝑳𝑳 f, r𝑳𝑳 o𝑹𝑹 m their long-run level, an additive adjustment\nis required to obtain the long-run level of a firm’s asset risk. This approach is consistent with patterns found in the data. When\nvolatility has been elevated over the past three years, it tends to be less elevated over the next year and vice-versa. Replacing\n2\nwith we obtain:\n2 𝛽𝛽\n2\n𝜎𝜎𝑓𝑓,𝑡𝑡\n2\n𝜌𝜌 ∙𝜎𝜎𝑠𝑠,𝑡𝑡\n( 21 )\n𝟐𝟐\n𝟐𝟐 𝟐𝟐 𝟐𝟐\n𝝈𝝈𝒐𝒐,𝒅𝒅\n𝟐𝟐 𝟐𝟐\n𝝈𝝈𝒐𝒐,𝑳𝑳𝑹𝑹 =𝝈𝝈𝒐𝒐,𝒅𝒅−𝝆𝝆 ∙𝝈𝝈𝑳𝑳𝟐𝟐 ,𝒅𝒅∙�𝝈𝝈𝑳𝑳,𝒅𝒅−𝝈𝝈𝑳𝑳,𝑳𝑳𝑹𝑹�\n2\n2 2 2 𝜎𝜎𝑠𝑠,𝐿𝐿𝐿𝐿\n𝜎𝜎𝑓𝑓,𝐿𝐿𝐿𝐿 =𝜎𝜎𝑓𝑓,𝑡𝑡∙�1−𝜌𝜌 ∙�1− 2 ��\n𝜎𝜎𝑠𝑠,𝑡𝑡\n2\n2 2 2 2 𝜎𝜎𝑠𝑠,𝐿𝐿𝐿𝐿\nTo put into words, the forward-looking adjustm𝜎𝜎e𝑓𝑓 n,𝐿𝐿 t𝐿𝐿 is= a 𝜎𝜎w𝑓𝑓 e,𝑡𝑡 ig∙h�t(e1d−-av𝜌𝜌er)ag+e 𝜌𝜌of o∙n 𝜎𝜎e 𝑠𝑠2 a,𝑡𝑡nd� the ratio between long-run systematic asset\nvolatility and short-run systematic asset volatility.\n3.3.3.2 Practice\nThe final step before calibrating is to choose statistical proxies for , , and . Our measure for is the weighted-\naverage of empirical asset volatility and modeled asset volatility, regarded in EDF8 as asset volatility. For the adjustment ratio, we\nuse modeled volatility to proxy 𝜌𝜌 and long-run modeled volatility 𝜎𝜎to𝑓𝑓 ,𝑡𝑡 pr𝜎𝜎o𝑠𝑠 x, y𝑡𝑡 𝜎𝜎. 𝑠𝑠,𝐿𝐿𝐿𝐿 𝜎𝜎𝑓𝑓,𝑡𝑡\nEstimation of long-run modeled\n𝜎𝜎\nv𝑠𝑠o,𝑡𝑡latility is closely tied to the short-run mod 𝜎𝜎el𝑠𝑠e,𝐿𝐿d𝐿𝐿 volatility (for brevity, modeled volatility).\nModeled volatility is composed of three additive terms, a financial statement-implied volatility, estimated at the firm-level, a\ncountry-level, short-run, fixed-effect, and an industry-level, short-run, fixed-effect, weighted by the firm’s percentage exposure to\neach industry. The estimation of short-run fixed-effects is updated once a month. For purposes of long-run modeled volatility, we\ntake a 100-month moving average of the short-run, fixed-effect parameters, and we use the resulting fixed-effects to calculate\nlong-run, modeled volatility. It is important for the long-run measure to not be conditioned on any particular phase of the business\ncycle, yet responsive to structural changes in an economy. Given National Bureau of Economic Research (NBER) data on\nrecessions during the Great Moderation16 suggest that recessions, peak-to-peak, have been about eight to nine years apart, we\nchoose 100 months as the window size.\nLast, we must calibrate . The constant has two types of effects on the final EDF measures. First, it changes the rank-order of\nDD, and, second, it has a mild impact on the time series of aggregate EDF measures by way of lowering the amplitude of credit\ncycles. We find that, wh 𝜌𝜌ile not strongly i𝜌𝜌dentified, is most suitably calibrated to 50%. Subsequently, this calibration results in a\nmild reduction of the amplitude of EDF cycles. In particular, among all the different time periods, we find aggregate EDF9 relative\nto aggregate EDF8 to be highest in the pre-financia𝜌𝜌l crisis year 2007. This finding is primarily due to this adjustment, although not\nthe only consequence of the forward-looking adjustments.\nIn fact, adjusting volatility to be more relevant in the future has increased the model’s early warning capabilities. In other words,\nEDF values of high-risk firms begin to rise earlier, hence, separating themselves from non-defaulters far before default.\n16 In this paper, the Great Moderations refers to the economic era started in the mid-1980s where both the economic cycles and inflation levels moderated.\n13 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 2 shows the effect of this adjustment on aggregate EDF levels. The green line is not subject to any adjustment, and the blue\nline shows the adjustment as calibrated under EDF9. It is noteworthy that the adjustment ratio raises EDF levels during the pre-\ncrisis year of 2006, while lowering it in the post-crisis year of 2010. As the population sample used in aggregation does change\nover time, it is helpful to look at a firm-level example. Figure 3 shows how different levels of forward-looking adjustment affects a\nfirm’s EDF measure.\nFigure 2 Effect of Forward-Looking Adjustment on Aggregate EDF Time series\nFigure 3 Effect of Forward-Looking Adjustment on Firm-Level EDF Time series\n14 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n4. Mapping Distance-to-Default to EDF Measures\nThis section explains how the EDF9 model transforms the Distance-to-Default to produce a probability, a key output. Since this\ntransformation is the most important calibration of the model, in the next subsections we cover the DD’s theoretical foundation,\nconceptual grounding, and implementation considerations. With EDF9, we update the calibration, incorporating data from the most\nrecent credit cycle. Further, we introduce a new financial firm specific mapping. Finally, we increase the upper bound of the EDF to 50%\nfor non-financial firms, and we discuss the reasoning behind these changes\n4.1 Concept\nThe Distance-to-Default concept provides an ordinal measure of default risk. In theory, the concept has the interpretation of a\nstandard deviation, so one could infer a probability. If the underlying stochastic process had a Gaussian distribution, then we can\nestimate the one-year EDF measure as:\n( 22 )\n𝒅𝒅𝟎𝟎 𝟏𝟏 𝟐𝟐\n𝒍𝒍𝒍𝒍�𝑷𝑷�+�𝝁𝝁𝒅𝒅−𝟐𝟐𝝈𝝈𝒅𝒅�\nФ�− 𝝈𝝈𝒅𝒅 �\nIn practice, we obtain more accurate results by empirically transforming the DD to the physical probability space, with a\nmonotonic function M()\n( 23 )\n𝒅𝒅𝟎𝟎 𝟏𝟏 𝟐𝟐\n𝒍𝒍𝒍𝒍�𝑷𝑷�+�𝝁𝝁𝒅𝒅−𝟐𝟐𝝈𝝈𝒅𝒅�\n𝑴𝑴�− 𝝈𝝈𝒅𝒅 �\nWe call the result the EDF credit metric.17\nIn the formula above, strictly speaking is the asset’s distance from default as of today. That distance is projected to become\n𝐴𝐴0\n𝑙𝑙𝑙𝑙�𝐷𝐷�\nby next year. When we s𝜎𝜎a𝐴𝐴y DD, what we intend is this projected value. Uncertainty surrounds this projected value.\n𝐴𝐴0 1 2\n𝑙𝑙𝑙𝑙�𝐷𝐷�+�𝜇𝜇𝐴𝐴−2𝜎𝜎𝐴𝐴�\nThe uncertainty is due to the economic shocks, both systematic and idiosyncratic, that affect the firm. Theoretically, the\n𝜎𝜎𝐴𝐴\ncumulative distribution function for that uncertainty is the cumulative standard normal distribution\nThe DD-to-EDF mapping is our calibration for the distribution of these economic shocks and is perhaps the primary\ncalibration of the model.\n𝑀𝑀( )\n4.2 Calibration\nWhen evaluating a model, an important question to ask is whether the calibration is relevant to “my” portfolio in the future. There\nare two aspects to this question: a cross-sectional one and a temporal one. “My portfolio” is a certain cross-section of all firms.\nTemporally, the calibration is to be used “in the future,” while it was estimated against historic data.\nA portfolio can be characterized by its geographic breadth, as well as the business types it covers. For instance, one may have a\nportfolio of firms concentrated in Southeast Asia, while another may have a portfolio of firms in Western Europe and South Africa.\nAs for business type, one may have a portfolio of only non-financial firms, whereas, another portfolio may be concentrated in\nbanks. Further, there is the idiosyncratic risk of individual names within the portfolio. Is relevant to different cross-sections?\nThe answer is in the conceptual role of . The Public Firm model produces probabilities, but with only a single factor. Hence,\n𝑀𝑀( )\ncalibration only involves estimating the distribution of the shocks. More specifically, we calibrate the model to parameterize the\nunanticipated component of default ris 𝑀𝑀k, (w )hile the factors in DD capture the anticipated and measurable ones. The anticipated\nones have become anticipated because a shock has been realized or a policy has been made and, hence, are observable.\nFor instance, after economic troubles hit Southeast Asia in 1997, investors anticipated increased risk, reflected in lower stock\nmarket valuations. Such valuations reduce , one of the factors in DD. But in 1996, Southeast Asia troubles were not anticipated,\njust as in early 2008, when the Great Recession was not anticipated.18\n𝐴𝐴0\nOn the one hand, a bank with a concentrated portfolio will possess risky assets that lead to a relatively high estimation of asset\nvolatility, which, in turn, is reflected in DD through . On the other hand, when a firm in need of cash taps into its credit line, we\n17 Crosbie and Bohn (2003) discusses the unsuitability of a Gau𝜎𝜎s𝐴𝐴 sian distribution.\n18 On August 29, 2008, the market did not anticipate a 30% reduction in the S&P 500 Index over the following three months.\n15 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\ncan observe its increased liability, reflected via the default point. In either case, DD captures the observable risk, while reflects\nthe risk of future shocks.\n𝑀𝑀( )\nWe may expect oil and gas exploration firms to experience elevated credit risk when energy prices fall unexpectedly. We may\nexpect the future earnings potential of such firms to decline with energy prices. To the extent that the market expects a decline in\nfuture earnings, the market capitalization of such firms would decline, which would lead to a decline in DD. The calibration of\nin turn, captures the likelihood of asset values falling in the future, with sufficient severity to lead to default.\nUnanticipated shocks need not be systematic and can hit individual names as well. For example, the EDF value of a specific firm\n𝑀𝑀( ),\nmay jump when a lawsuit is announced, which leads to a decline in stock price. We can interpret the calibration of as the\nparameterization of the distribution of both systematic and idiosyncratic credit risk shocks. In other words, captures the\nmagnitude of different shocks and the frequency at which they hit. As shocks are not bound by geography or busine𝑀𝑀ss( m)odels, we\nassess the calibration to be relevant across macroeconomic environments. 𝑀𝑀( )\nIn making a calibration relevant for use in the future, in our view, it is better to calibrate to a longer history.\nIf we calibrate to only one credit cycle, we would see many idiosyncratic firm-level shocks, while only having a limited number of\naggregate shocks. As we include more history, we include more systematic shocks into the calibration, which provides a more\nrobust calibration compared to a model that uses a relatively shorter window. By extension, if a certain credit cycle is included, it is\nimportant to cover it in-full, as partial inclusion can skew the observed distribution of shocks.\nA firm’s DD is intended to control for the future earnings potential of the company as anticipated by the equity market. Moreover,\nthe DD reflects the firm’s business practices, the industry and the country that the firm resides in, and the current state of the\neconomy. What DD cannot control for are the unanticipated economic shocks — both aggregate and idiosyncratic. The DD-to-\nEDF mapping intends to capture the magnitude and likelihood of these unanticipated events. In our view, a larger calibration\nsample makes for a more robust DD-to-EDF.\n4.3 Implementation\nWhat’s New in EDF9: We update the DD-to-EDF calibration by adding the most recent credit cycle\nThe process of building the DD-to-EDF mapping involves determining the frequency of realized defaults, conditional on the credit\nrisk level. Figure 4 shows the EDF credit metrics and observed default frequency (ODF) for 50 different credit risk levels,\ndetermined by grouping 25 years of rated, non-financial corporate observations into equally-sized buckets. Figure 4’s blue line can\nbe thought of as the DD-to-EDF mapping, had DD’s been discretized at 50 levels. The orange dot represents the percentage of\ndefaults within each bucket, and, like the estimator for the binomial parameter, its standard error, in part, depends on the number\nof flagged observations. Hence, we see more sampling variability on the right end of the spectrum, when compared to the left.\nThe blue line is a flexible function form with sufficiently many degrees of freedom to fit through the orange dots. The parameters\nare estimated, such that, the mapping function performs well on a variety of different subsets.\nAt any point on the credit risk spectrum, the mapping function intends to estimate a probability of default that is consistent with\nthe realization of default over an extended period of time.\n16 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 4 DD-to-EDF Mapping vs. Observed Default Frequency\n4.4 Defining Default\nWe regard a company in default if it does not make a payment on a debt obligation when due at maturity date. We record the\nevent as the date of the missed payment and do not take into account grace periods given by the lender. This definition is more\nconservative relative to Basel II, which regards 90-days past due as default.19 When a lender extends the maturity date of a debt\nwhile the company has limited access to funds and limited profit generation, if we find that to have been to prevent bankruptcy or\ndefault, we regard it as a default. A distressed exchange is also treated as a default, where debt is exchanged for equity and a loss\nof seniority or a decrease in principal or interest amount occurs. Furthermore, the default of a wholly-owned subsidiary that\nrepresents more than half of the sales or assets of the public parent company is regarded as default of the parent company. Last,\nwe keep track of bankruptcies and liquidations as well.\nFor financial firms, we consider government bailout as a type of default. We look for indications as to whether the firm would have\ndefaulted without the received support. Many banks receive government funding for a variety of reasons. We only consider the\nreceipt of government funds as a bailout if, in our judgment, the funds are provided for the purpose of avoiding a default on the\npart of the bank.\n4.5 Financial Firms\nWhat’s New in EDF9: We introduce a financial firm-specific DD-to-EDF calibration.\nIn Section 3.2.1, we discussed how our approach results in a different default point definition for financial firms. Here, we discuss\nthe implications to the DD-to-EDF measure mapping.\nA financial firm’s financial statements are fundamentally more opaque than non-financial firm statements. This opaqueness affects\nthe DD’s information content and, subsequently, its conditional distribution. For the purpose of DD-to-EDF measure mapping, this\ndifference implies that a calibration sample including non-financial corporations should not be used. If we preserve the relation\nthat Figure 4 implies between DD and EDF measure, but change the sample to financial firms, we obtain Figure 5\n19 Refer to Basel Committee on Banking Supervision (2004).\n17 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 5 DD-to-EDF; Financials vs. Non-Financials\nFigure 5 is significant for many reasons. First, while there are cases of default among publicly traded financial firms in the past,\nprior to the financial crisis in North America and Europe’s double-dipping financial crisis, there were not enough observations to\nidentify the relationship that the orange dots in Figure 5 demonstrate.\nThe second significance is the implied slope. As the opaqueness of a financial firm’s statements reduces the signal-to-noise ratio of\nthe market signals, the EDF measure would have to be less sensitive to market changes than in the case of non-financial\ncorporations. The default data confirms that a change that moves a financial firm’s DD from, say, bucket 30 to bucket 25, warrants\na smaller increase in the EDF measure than it would have had it been a non-financial firm.\nAs a benefit of having a financial firm-specific mapping, we do see more stable EDF measures in EDF9 when compared to EDF8.\nThis finding implies that the riskiest financial firms in a bad stage of the cycle look safer under EDF9, but it also implies that the\nsafest firms in a good stage of the cycle look riskier under EDF9. This result follows also, in part, because the sample includes\nbailouts, which can raise default frequency for the low-risk DDs. We include bailouts in the sample, as the model reflects the firm’s\nstand-alone credit risk. Over time, as macroeconomic fluctuations move the distribution of firms across the DD spectrum, EDF9\nmay result in a more stable measure of portfolio level risk and capital requirements for financial firms.\n4.6 Upper Bound\nWhat’s New in EDF9: We increase the upper bound to 50% for non-financial corporations, but keep the upper bound at 35% for\nfinancial firms.\nEDF9 provides extra granularity for high-risk corporate names when compared to prior versions. Firms in financial distress may\navoid default in several ways. One common way occurs when another firm buys the distressed firm at a low price, assumes\nownership of the assets, and honors the debt (e.g., JPMorgan’s acquisition of Bear Stearns or Wells Fargo’s acquisition of\nWachovia). Consequently, prior to the default event, the EDF measure is always less than 100%, and the upper bound on the EDF\nmetric is an empirical question. By studying graphs similar to Figure 4 but with more granularity in the number of buckets, we\n18 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nconclude that capping the EDF metric at 35% results in an under-estimation bias for EDF9. In other words, the model’s separation\npower among the very high-risk names has increased so much, it is appropriate to distinguish between observations with a 35%\ncredit risk and those with a 50% credit risk.\nFigure 6 DD-to-EDF Measure; Upper-Bound for Non-financial Corporations\n19 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 7 DD-to-EDF Measures; Upper-Bound for Financial Firms\nFigure 6 shows what Figure 4 would have looked like, had we used 200 buckets instead of 50. Each DD observations bucket is now\n1/4th smaller and sampling variability is naturally more pronounced. But focusing on the left end of the graph, the first orange dot\nof Figure 4 has now split into the first four orange dots of Figure 6. Graphs similar to this one, created with a variety of different\nbucketing schemes, allow us to study the EDF level for the highest-risk names. The EDF measure is now capped at 50% for non-\nfinancial corporates. Figure 7 shows the same study for financial names. In this case, we can see that, consistent with the flatter\nmapping function, the EDF level does not peak as high as it does for non-financials. As suggested by the data, the cap remains at\n35% for financial firms.\n4.7 Performance in Different Portfolios\nOn the one hand, many models in the option pricing literature — the Merton model for instance — have made the Gaussian\nassumption for this distribution. On the other hand, the data consistently rejects this assumption. Instead of the cumulative\nnormal distribution, the Public Firm EDF model uses physical realization of default to obtain the most accurate assessment of the\nrelation between the DD and EDF measure. This process requires the collection and construction of a database of default events,\nan endeavor that Moody’s Analytics has been engaged in for more than two decades. This research creates a database of 10,000-\nplus default events, temporally spanning many decades and cross-sectionally, covering firms across the globe.\nDefault collection is a challenging and resource-intensive endeavor, for many reasons. There are more than 35,000 firms, spread\nglobally, and the breadth of the sample is rapidly expanding. Second, firms are subject to different disclosure requirements and\noperate under different legal environments. The information is also disseminated in a variety of different languages. Furthermore,\noperationalizing default definitions for small firms, as well as those subject to government intervention, can be challenging. All of\nthese issues impose notable restrictions on the calibration sample of DD-to-EDF measure mapping. As important as temporal\ndepth and cross-sectional breadth of the sample are, it is also important to make sure default collection is comprehensive. We\nrestrict the calibration sample to a subset of the overall population to ensure that the default collection is reliable.20\n20 For more on challenges of default collection, please refer to Section 3.1.2 Dwyer and Qu (2007).\n20 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nIn the universe of rated firms, we view the coverage of defaults as comprehensive. Among non-rated firms in North-America and\nEurope, we view the coverage to be close to comprehensive for firms among the top-90% of liabilities. In Appendix C, we discuss\nhow we define the top-90% and what it means for firms of different sizes.\nFor any sample chosen for such calibration, sampling variability is always present. To properly account for this issue, we construct\nmany different samples with sufficient depth and breadth. We then ensure that, for any point on the credit risk spectrum, the EDF\nmeasure is an appropriate reflection of credit risk, allowing for sampling variability.\nFigure 8 shows some of this effort. The left panels shows sampling variability resulting from looking at different recessions, within\ndifferent regions. The right panels show looking at different cuts of firms, within different regions. Specifically, the right panels\nshow the DD-to-EDF measure mapping properly captures the slope and curvature for the different samples. We find the different\nlevels suggested in the bottom right graph reflects the challenges involved in comprehensive default collection for that sample,\nbut it also indicates that the slope and curvature of the mapping function is just as prudent for the top-99% sample as it is for the\ntop-90% sample.\nEDF9, when compared to its predecessor, benefits from more sample depth and breadth. The EDF9 data includes the Great\nRecession, as well as its recovery years. Furthermore, for the first time, the Public Firm EDF model expands the calibration sample\nto include global firms. We now include any rated firm, regardless of location or size, in the calibration sample.\n21 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 8 Sampling Variability in Observed Defaults\n22 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n5. Assessing Public Firm EDF Model Performance\nThere are many performance metrics with which a credit risk model can be assessed. This section presents the conceptual grounding for\nsome of the tests we perform and shares some results. For more details, please see Moody’s Analytics “Public EDF Validation” (2015).\nAssessing the performance of the ordinal measure of default risk is a different problem from that of the cardinal measure of\ndefault risk. In other words, producing prudent probability levels does not imply high rank-ordering power, and inversely high rank-\nordering power does not imply properly calibrated PD levels. As a result, we have a set of tests for Distance-to-Default assessing\nthe model’s rank-ordering power and another set for the EDF measure, assessing the probability levels.\n5.1 Rank-Ordering Power of Distance-to-Default\nThe Accuracy Ratio (AR) measure produces a ratio between -100% and 100%, quantifying a model’s accuracy in separating default\nobservations from others. An AR of 100% is a “perfect model,” and a model no better than a random model has an AR of 0%. A\nnegative AR indicates that the model is calling safe firms risky, and vice-versa.21\nTake for example a model rank-ordering twelve hypothetical firms.\nTable 1\nRank-ordering of 12 Hypothetical Firms\nFIRM A B C D E F G H I J K L\nDefaulte No No No Yes No Yes No Yes No Yes Yes Yes\nPD 1bp 3bps 10bps 40bps 70bps 1% 2% 5% 10% 20% 30% 50%\nFurther, suppose we have a probability of default model that enables us to rank-order the firms by the produced PD. There are\nmore defaulted firms among the high-risk names and fewer among the low-risk names, so the model is performing as expected,\nbut it is not perfect. The AR helps us quantify this fact.\nOf the twelve names, six have defaulted, so ideally, when looking at the riskiest half of the subset, we should find all the defaulted\nnames. And when looking at the riskiest quarter, we should find half of the defaulted names. We can plot the percentage of\nobserved defaults below each risk level, for a variety of different risk levels.\nIdeally, a model rank-orders perfectly and produces results such as the green bars shown in Figure 9. Realistically, the noise and\nuncertainty in the future result in model performance that does not perfectly overlap with the green bars. A random model results\nin a lower triangular shape, with the top of its bars connecting the lower left corner to the upper right corner with an\napproximately straight line.\n21 Traditionally, the Accuracy Ratio is derived from a Cumulative Accuracy Profile (CAP). Closely related to a Cumulative Accuracy Profile is a Received\nOperating Characteristics (ROC) curve. Typically, a Gini coefficient is derived from an ROC curve. A Gini coefficient can be shown to be equal to an AR.\n23 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 9 Cap Plot for the Hypothetical Example\n1.00\n0.90\n0.80\n0.70\n0.60\n0.50\nIdeal\n0.40\n0.30 Model\n0.20 Random\n0.10\n0.00\nBy convention, the ideal model has an accuracy ratio of 100%, and the random model has an accuracy ratio of 0%. For anything in\nbetween, the value of the accuracy ratio is the percentage of overlap between the model’s bars and ideal bars, for the area bound\nbetween the two extremes of ideal and random. In our case, the blue bars have a 67% overlap with the area bound between the\ntop of red bars and the top of green bars. As seen in Figure 9, the bars form the Cumulative Accuracy Profile, also called the CAP\nplot.\nFor a real-life case, Figure 10 looks at a set of global rated firms, spanning 1987 – 2012, resulting in about 600,000 observations,\nabout 1.6% of which are default observations.\n24 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 10 Global Rated Firms, 1987 – 2012\nNext, we rank-order the firms using four different statistics. The first is the book-equity / book assets ratio introduced in Section 3.\nIn the plot, it is called “Book Leverage.” The second measure is market capitalization as a percentage of firm value, coming from\nreplacing book values of equity with market values of equity. This statistic is labeled “Market Leverage” and shows that a market-\nbased measure of equity is more useful for understanding credit risk than book equity.\nThe third statistic is the risk-adjusted measure of market leverage, defined as:\n𝐴𝐴−𝐷𝐷\nIn Appendix B, we show that this ratio is an approximation of D 𝐴𝐴D ∙, 𝜎𝜎a𝐴𝐴nd it can be thought of as a risk-adjusted measure of market\nleverage. The numerator is the difference between asset value and default point, and the denominator is asset value multiplied by\nasset volatility. The CAP plot shows it performs better than market leverage. The AR of this measure is the area between the dark\ngreen line and red line, which, against this dataset, happens to be 78%.\nFor the fourth statistic, we look at the EDF measure. We see that the EDF curve is closest to the ideal line and furthest away from\nthe random line. The accuracy ratio of the EDF measure is the area between the blue and red line, as a percentage of the area\nbetween the green and red lines, and, for this particular dataset, equals 83%.\n5.1.1 Important Accuracy Ratio Caveats\nIt is important to note a few caveats regarding AR. First, when comparing the AR of two different models, it is important to ensure\nthat they are measured on the same sample, as the particular value of AR depends on both the model and the sample. If we apply\nthe same model to two samples, where the one sample has firms with very similar levels of risk, and the other has very different\nlevels of risk, the AR of the sample with very different levels should be higher.\nSecond, AR does not make a statement about the model’s out-of-sample properties. The out-of-sample properties must be\nstudied separately. In other words, a model can achieve a very high AR on a specific dataset, but perform poorly on other, different\n25 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\ndatasets. For a structural model, the out-of-sample rank-ordering properties tend to be strong, as there are very few calibrated\nparameters. The out-of-sample performance is more of an issue when comparing a structural model to an econometric model or\nwhen comparing a structural model to a model that uses machine learning techniques.\nThird, AR is a statistic with a standard error and should be interpreted with regard to that. For example, an EDF measure’s AR of\n83%, while larger than risk-adjusted market-leverage’s AR of 78%, may not be statistically significantly different.\nFourth, AR can be studied at a variety of different horizons. While we can study a model’s separation power upon default, we can\nalso do so six months before default or 36 months before default. What we learn from these studies is the model’s early warning\ncapability. Typically, a model has a higher AR when predicting default at shorter horizons.\n5.1.2 Importance of Accuracy Ratio Standard Error\nIn this section, we stress the importance of understanding the distribution of accuracy ratio. For more technical details on the\naccuracy ratio, its statistical cousins, as well as distributional characteristics, refer to Engelmann (2003).\nTable 2\nHypothetical Example on Rank-Ordering\nFIRM A B C D E F G H I J K L AR\nDefaulted No No No Yes No Yes No Yes No Yes Yes Yes\nPD 1bp 3bps 10bps 40bps 70bps 1% 2% 5% 10% 20% 30% 50%\nSubset 1 x x x x x x x x x x x x 67%\nSubset 2 x x x x x x x x 25%\nSubset 3 x x x x x x x x 100%\nSubset 4 x x x x x -33%\nLet us begin with our earlier example. While the AR of our hypothetical PD model was 67%, that value differs against different\nsubsets of the data.\nIn Table 2, four different subsets of the data result in four very different AR values, even one producing a negative value, suggesting\nthe rank-order is incorrect and worse than a random order. Table 2 illustrates the effect of sampling variability on AR.\nFigure 11 Bootstrapped AR (left panel); Early-Warning at Longer Horizons (right panel)\n26 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nOne solution to this issue is to bootstrap the difference between the ARs of different samples. Take for example rated corporations\nduring the recent business cycle. If we take the more conservative of Moody’s and S&P’s ratings, we obtain an AR of 78%. If we\ntake the EDF measure, however, we obtain an AR of 86%. But are these measures statistically significantly different? We can\nbootstrap the distribution by constructing, say, 100 different random subsets. On each subset, we calculate the AR using both\nrating and EDF measure and note the difference. We then identify the percentages that were positive to determine significance. In\nFigure 11 (left panel), we fit a non-parametric distribution to the observations. This figure illustrates the test, showing the null-\nhypothesis was rejected.\nIf we obtain a distribution centered around zero, it means that, even though the two methods have different rank-ordering powers\non different subsets, one is as likely to be better as it is to be worse. Hence, neither model can be declared better that the other.\nIn the case of EDF measures vs. agency ratings applied to the non-financials during the recent business cycle, we see in Figure 11\n(left panel) that the distribution is significantly to the right of zero, indicating we can infer EDF measures have a higher rank-\nordering power.\n5.1.3 Accuracy Ratio at Different Horizons\nWhile we calculated all the AR’s reported earlier in this section over a 12-month horizon, there are valuable details in studying\nother horizons as well. Figure 11 (right panel) presents the accuracy ratio as a function of the months from default. We calculate\nthe ARs as follows. We construct a sample in which we include all the good observations, but for each defaulting firm we only\nretain the observations within X months from the month of the default event. In Figure 11 (right panel), the X axis represents the\nnumber of months between the observation date, and the y-axis is the corresponding accuracy ratio. We see one-year ARs of the\nprevious section as y-values of 86% and 78%, corresponding to where the x-axis is labeled -12. As we move further away from\ndefault, we see a reduction in the AR.\nWhen analyzing a model with such graphs, there are two aspects to note: the level of the line and its slope. A higher level indicates\nhigher rank-ordering power, controlling for horizon. The slope indicates the pace at which early-warning power is lost. When\ncomparing two models, it is useful to note whether their lines cross and, if so, at what horizon. When the lines of two models\ncross, it indicates one is better for early-warnings, while the other outperforms for firms closer to default.\n5.2 Temporal Characteristics of EDF Levels\nAs discussed in Section 4, by construction, the mapping function is consistent with physical default rates over an extended period\nof time using a panel dataset. One can also compare the time series average of EDF measures to the observed default frequencies\n(ODF).\nWhile an intuitive concept, defining ODF concretely is more challenging than may initially appear. “Default Intensity” is one way\nto define ODF. Before trying to interpret the graph, it is important to understand this definition and its limitations. Figure 12\ncompares one definition of ODF against EDF. To construct the orange line, each month, we look at the percentage of firms with an\nEDF at the end of the month and compute the percentage that default in the next month. Then we fit a Hodrick-Prescott (HP)\nfilter through it to get the default-intensity.\n27 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 12 Time Series of EDF vs. Default Intensity\nWe use an HP filter because the default data is otherwise quite noisy. Figure 13 shows the “Instantaneous Default,” which is the\nannualized, monthly observed default rate in Figure 12, but before applying the filter.\nFigure 13 Time Series of EDF vs. Instantaneous Defaults\nThe orange lines in Figures 12 and 13 represent the same underlying information, however one masks the sampling variability in\nthe data by smoothening the time series. In interpreting Figure 12, there are two aspects of the model to note: its lead against\ndefaults and its level compared to defaults. There are three notable periods of sudden increase in risk, 1998, late 2000, and 2008.\nFigure 12 shows the model leading the default events by more than a quarter. To interpret the information regarding level, we\nmust be cognizant of three things.\nFirst, while Figure 12 suggests the EDF levels are appropriate in the left half but high in the right half, we must not forget that the\nsampling variability presented in Figure 13 is actually hidden in Figure 12. Sampling variability causes noisy default data. The\nmodel, however, intends to capture the underlying default intensity, and, by visual inspection of Figure 13, the model is fairly\nsuccessful at that. To appreciate the importance of sampling variability in assessing EDF levels, we can look at two different time\nperiods as examples. First, looking at the first half of 2009, Figure 12 suggests the EDF value over-predicts. However, looking at\nFigure 13 makes it clear that default rates peak at levels close to the EDF level peak. As another example, focusing on 2002, on the\none hand, Figure 12 suggests that in the first half of the year the model was moving in the opposite direction of default rates,\nreaching seemingly over-stated EDF levels by the second half. On the other hand, looking at Figure 13, we find multiple months in\n28 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n2003 with default rates comparable to levels predicted by EDF level. These default rates are masked in Figure 12’s filter. In this\nrespect, the model is doing a fine job capturing risk levels in different times.\nSecond, while the model does not over-predict at the peak of 2009 recession, one can argue that EDF levels are often slightly\nhigher than actual default rates during 2008. It is important to reflect back on the early period of the Great Recession, as financial\ninstitutions experienced pressure, the credit markets were squeezed, and the future looked bleak. At first, policy response was\nunknown, and subsequently, when the quantitative easing policy was announced, its implications were untested. In hindsight, we\nknow the Great Recession, as bad as it was, was not as bad as early predictions indicated.22 Likewise, a market-based model should\nbe expected to stay true to the ex-ante assessments of credit risk and not reflect what one would have predicted if one had perfect\nforesight.\nThird, the data censoring that results from defaulting is not limited to the month of default. It does happen that an exchange\ndelists a firm shortly prior to its default event. To that extent, the default intensity measure can be downward biased.\nWe remedy this issue by flagging the twelve months leading the default events and looking at the percentage of flagged\nobservations each month. Alternatively, we can flag the twelve months trailing the events. The following table explains the process\nwith an example.\nTable 3\nDifferent Definitions of Default Flag\nDATE TIME TO DEFAULT INSTANTANEOUS 12-MONTH LEADING 12-MONTH TRAILING\n2001-03 -15 0 0 0\n2001-04 -14 0 0 0\n2001-05 -13 0 0 0\n2001-06 -12 0 1 0\n2001-07 -11 0 1 0\n2001-08 -10 0 1 0\n… …\n2002-03 -3 0 1 0\n2002-04 -2 0 1 0\n2002-05 -1 1 1 0\n2002-06 0 - - 0\n2002-07 1 - - 1\n2002-08 2 - - 1\n2002-09 3 - - 1\n… …\n2003-01 7 - - 1\n2003-02 8 - - 1\n2003-03 9 - - 1\nTable 3 shows a firm that defaulted in June of 2002, as an example of different ways an observed default time series can be\nconstructed. The “12-Month Leading” corresponds with what the EDF measure would be were one to know the date of default 12\nor more months ahead of time with perfect foresight. Such a model with perfect foresight has an EDF of 0% until 12 months\nbefore default, subsequently hits 100% twelve months before default, and then remains there until default. Although not immune,\nthe 12-month leading definition is less susceptible to data censoring than the instantaneous measure.\nThe advantage of the 12-month trailing method is in producing results more comparable to the rating agency’s statistics. However,\nsince the example in Table 3 was pulled from the stock market nine months after default, constructing a trailing measure of\ndefault for a market-based model requires special consideration to account for data-censoring.\nFigure 14 shows EDF measures next to the ODF, as defined by the 12-month leading definition. While the model lags the orange\nline, it does not lag the default event, but rather a hypothetical model with perfect foresight of at least twelve months.\n22 After hitting a bottom in March of 2009, the Dow Jones Industrial Average grew by 60% during the following 12 months and another 15% during the next\n12 months.\n29 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 14 Time Series of EDF vs. Model with Perfect Foresight\n30 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n6. Conclusion\nEach day, after market close, Moody’s Analytics’ Public Firm EDF model processes the credit risk of some 35,000 firms globally,\nproducing a default probability named the EDF credit measure. At a very high level, the measure constitutes a Distance-to-Default\nfor each firm and a transformation of the DD into an Expected Default Frequency (EDF).\nThe DD is built on the causal relationship between default and economic drivers of defaults. It can be heuristically thought of as a\nrisk-adjusted measure of market leverage. The risk adjustment accounts for the business model and its effect on the risk of future\ncash flows. The market leverage is a ratio of market value of assets, a valuation reflecting net present value of future cash flows,\nand the default point.\nThe transformation of DD to physical probability space is such that, at all credit risk levels, the EDF measure is consistent with\nphysical realization of default over an extended period of time. This transformation is calibrated against a global set of firms, spans\nmultiple credit cycles, and is applicable to different macroeconomic environments.\nThe 9th generation of the Public Firm EDF model is the continuation of the path laid down by KMV in the field of structural credit-\nrisk modeling. The new version continues as a structured option-pricing based model and calculates the put option, i.e. the\ndifference between the risk-free value of liabilities and the risky value of liabilities, using the same formula as its predecessors. The\nprimary model drivers continue to be asset value, default point, and asset volatility.\nWe have refined the estimation of the drivers and have updated the calibrations. These changes incorporate the experience of the\nmost recent credit cycle, as well as the increase in the number of public firms globally.\nThe Great Recession deepened our understanding of financial firms. There has been a general understanding that financial firms\nhave a special business model, with special credit risk implications. Given the benefit of more data, we have been able to take this\nintuition and incorporate it into model implementation. In improving the default point, EDF9 now uses a more parsimonious and\ntransparent formula. This formula has the advantage of increased stability when compared to its predecessor, which, in\nconjunction with its transparency and its replicability, results in more intuitive movements in firm-level EDF measures for financial\nfirms. Another improvement is with the DD-to-EDF mapping, where a financial-firm specific mapping now results in more prudent\nEDF levels for financials, as well as more prudent changes to the EDF level in response to observed events. After making all these\nchanges, we see an increase in EDF9’s accuracy ratios for financial firms over EDF8.\nThe measure of asset risk, which adjusts market leverage, has also been improved in several ways. Most notably, benefitting from\nthe global expansion in equity markets, we now model asset volatility at a much more granular level. The asset volatility of each\nfirm is individually calculated using its de-levered equity returns, and that measure is adjusted for sampling variability using our\nmodeled asset volatility. Location is one of the three factors in modeling asset risk, and with EDF9 we now define it at the country\nlevel, as neighboring countries within a region may be subject to different asset risk cycles. Furthermore, asset risk is now adjusted\nto be more relevant to the next year. This results in a more point-in-time measure, also more stable at an aggregate level. Last, we\ncan now compute asset returns using weekly returns over a three-year window globally, whereas, EDF8 used monthly returns over\na five-year window outside of North America.\nOverall, the most significant improvement is with our ability to address financial firms better. As the EDF metric is now calibrated\nto the actual failure of financial institutions, stemming from data that now includes the Great Recession period, we have a more\naccurate measure of the stand-alone risk of such firms. Also, relative to EDF8, the EDF 9 credit metric is more stable for financial\nfirms. The EDF9 metric provides a timely alternative view to the agency ratings of financial institutions.\nFor non-financial firms, the EDF metric continues to be a valuable early warning risk tool that incorporates the most recent\ninformation available on both the firm and the business environment in which it operates.\n31 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nAppendix A The Public Firm EDF Model within the Context of Moody’s Analytics Credit Risk\nSolutions\nMoody’s Analytics Public Firm EDF model is the core model behind the product commercially known as CreditEdge and its\npredecessor Credit Monitor. The core model is also used in a variety of other products and hosts many alternative credit risk\nmodels. This section introduces these related products and models.\nEach day, the EDF model processes data for a comprehensive set of approximately 35,000 firms, spread globally over almost 90\ncountries. The resulting statistics, most notable of which is the one-year EDF, are provided to users through multiple channels.\nOne such channel is the website platform creditedge.com. Users can also access model data with an Excel Add-in that allows\ndirect downloading model values into an Excel sheet. Additionally, with the Data File Service (DFS), clients can retrieve data as\nflat-files via an FTP server. Last, a WebAPI allows for programmatic access.\nBeside the one-year EDF, CreditEdge delivers alternative measures of credit risk, using models that build upon the basic Public Firm\nEDF model. These include the Term Structure model, the Valuation model, the Stressed EDF model, and the Through-the-Cycle\nmodel. We also provide a product feature that enables estimating a firm’s rating based upon its EDF credit measure — an EDF-\nimplied rating. Finally, our RiskCalc product uses Distance-to-Default to adjust the default risk of private firms for the current stage\nof the credit cycle.\nThe Term Structure model estimates a term structure of EDF values to measure credit risk at different horizons, between one to 10\nyears. While, in the short-term, a firm is subject to both idiosyncratic and systematic risks, over longer periods of time, spanning\nthe duration of a business cycle, the idiosyncratic risks dominate, giving the credit risk measure acyclical properties. Such long-\nterm EDF measures can be used for valuing long-duration exposures. Longer-term EDF metrics are more stable, which may make\nthem more suitable for capital requirement calculations.\nThe EDF-implied rating estimates a rating for every non-rated firm in the CreditEdge database, as implied by its EDF metric, as well\nas the nine EDF values on its term structure. The relationship between EDF credit measures and agency ratings can be calibrated\nbased on either Moody’s ratings or Standards & Poor’s ratings. This feature enables an estimate of what a firm’s ratings would\nhave been, had it been rated. For rated firms, the EDF-implied rating enables studying the difference between the market\nsentiment, as reflected through a structural quantitative model and that of fundamental analysis done by rating agency analysts.\nFurthermore, as the EDF metric often responds faster to changing market conditions, the EDF-implied rating may also be used to\nspeculate on rating upgrades and downgrades.\nWhile the EDF measure reflects information embedded in the equity markets, the Valuation model can be used to better\nunderstand the credit risk priced into credit default swaps (CDS) or bonds. The Valuation model also enables estimation of the\nCDS implied by the EDF measure. This information can be useful in both mark-to-market valuation of illiquid instruments, as well\nas in developing trading strategies.\nThe Stressed EDF measures model credit risk conditional on macro-economic factors. In other words, we can devise a hypothetical\nmacroeconomic scenario and then study the effects on firm-level credit risk by producing conditional EDF measures. Stress testing\nis the most common use case of Stressed EDF measures. The Through-the-Cycle EDF model produces EDF measures that have\nbeen filtered to remove the credit cycle. The TTC EDF metrics reflect the firms’ underlying long-run credit risk.\nAnother related product is Moody’s Analytics RiskCalc, RiskCalc produces private firm EDF measures to produce a forward-looking\ndefault probability by combining financial statement and a credit cycle adjustment into a highly predictive measurement of stand-\nalone credit risk for private firms. The credit cycle adjustment uses the Moody’s Analytics Public EDF model to adjust the risk of\nprivate firms to reflect the recent trends in public firms in comparable regions and industries.\nAll the related and extended EDF models produce the credit risk of a single obligor. When many exposures are aggregated into a\nportfolio, quantifying the resulting portfolio risk poses another set of challenges. Tackling that problem requires knowledge of\nexposure correlations. For that purpose, Moody’s Analytics offers the Global Correlation Model23 or GCorr. The GCorr model uses\nasset returns derived from the core Public EDF model to estimate correlation of different firms. RiskFrontier calculates the loss\ndistribution of a portfolio, where key inputs are EDF metrics and correlations.\n23 For more details please refer to Huang (2012).\n32 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nAppendix B Conceptual Grounding of the Public Firm Model\nThis section is intended for those new to the Public Firm model framework. It conveys the conceptual grounding of the model by taking\na balance sheet approach, beginning with leverage.\nWe seek to build models with a solid intuitive foundation that perform well and are applicable. Critical to model application is the\nassessment of the reasons behind output change and without a transparent and intuitive structure such assessment is out of reach.\nSince the thought process behind the Public Firm EDF model is one of studying the causal relation between default and the\neconomic drivers of default, there is a very grounded intuition behind its structure. At the heart of the model is a rank-ordering\nstatistic, Distance-to-Default (DD), which can be thought of as an evolution of a balance sheet-based measure of leverage. This\nsection explores the intuition behind DD. To explain this intuition, we incrementally refine the balance sheet-based measure of\nleverage, in four steps. In each step, we describe a refinement and illustrate its value using an example. We then arrive at a\nheuristic definition of DD.\nThe balance sheet measure of leverage we begin with is the ratio of book equity to book value of total assets, perhaps one of the\noldest tools in credit analysis. At its core, the Public Firm EDF model is not a different paradigm, but rather a modern approach to\nmeasuring this value. Indeed, the result is a credit metric we can describe as risk-adjusted market leverage. In other words, the\nmeasure can be thought of as a leverage, measured with market valuations, and adjusted for asset risk. Through the next set of\nexamples, we consider each in turn.24\nTable 4 summarizes the four definitions of leverage we consider, each an incremental refinement of the prior.\nTable 4\nDifferent Leverage Definitions\nUSING\nBook values\n𝐵𝐵𝑂𝑂𝑂𝑂𝑆𝑆 𝐸𝐸𝐸𝐸𝑃𝑃𝑂𝑂𝐴𝐴𝐸𝐸\nEquity market values\n𝐵𝐵𝑂𝑂𝑂𝑂𝑆𝑆 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝑇𝑇𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝐶𝐶𝐶𝐶𝑂𝑂𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶𝑂𝑂𝐶𝐶𝐶𝐶𝐴𝐴𝑂𝑂𝑂𝑂𝑂𝑂\nMarket Value of Assets\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝐶𝐶𝐶𝐶𝑂𝑂𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶𝑂𝑂𝐶𝐶𝐶𝐶𝐴𝐴𝑂𝑂𝑂𝑂𝑂𝑂+𝑇𝑇𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶 𝐿𝐿𝑂𝑂𝐶𝐶𝑎𝑎𝑂𝑂𝐶𝐶𝑂𝑂𝐴𝐴𝑂𝑂 𝐴𝐴𝐴𝐴\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴−𝐿𝐿𝑂𝑂𝐶𝐶𝑎𝑎𝑂𝑂𝐶𝐶𝑂𝑂𝐴𝐴𝐴𝐴𝐴𝐴\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴\nTerm structure of liabilities\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴−𝐷𝐷𝐴𝐴𝐷𝐷𝐶𝐶𝑃𝑃𝐶𝐶𝐴𝐴 𝑃𝑃𝑂𝑂𝑂𝑂𝑂𝑂𝐴𝐴\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴\nFor the first example, we compare two firms, Eastman Kodak and Cablevision System Corporation. We find that six months before\ndefault, Eastman Kodak had a leverage ratio of -22%, indicating that book liabilities exceeded book assets. Kodak was an early\npioneer in film photography, but Kodak was unable to successfully adapt its business model to the innovation of digital\nphotography. Nevertheless, companies can have a negative net worth for a variety of reasons and yet still maintain an\neconomically viable business. Indeed, in the same month, Cablevision Systems Corp. had a leverage ratio of -72%, yet it has not\ndefaulted to date. The relevant reason was not reflected in the balance sheet, but it was accounted for by the equity market. The\nmarket capitalization of a company reflects the markets’ perception of the future earnings of a company. Consequently, market\ncapitalization is more forward-looking than book equity, and, in our view, it is more useful for understanding the credit risk of a\ncompany. If we define leverage as market capitalization as a percentage of the firm value, where firm value is market cap plus total\nliabilities, we find Kodak’s leverage ratio was 8% and Cablevision’s 31%. In other words, by using market capitalization, we can\nactually rank-order Kodak as riskier than Cablevision.\n24 We study each pair six months before the default of the defaulting member of the pair. In these examples, the financial statement is actually one quarter\nprior to the market date to allow for time for both the firm to finalize the statements, as well as time for the vendors to process the statement into a data\nfeed. In one case, there is a two quarter lag, as that firm only produces semi-annual statements.\n33 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nTable 5\nBook Value of Equity vs. Market Capitalization\nEASTMAN KODAK CABLEVISION SYSTEM CORPORATION\nBook Equity -1,274 -6,462\nBook Assets 5,882 8,963\nMarket Capitalization 646 7,008\nTotal Liabilities 7,156 15,425\nBook Equity / Book Assets -22% -72%\nMarket Cap / ( Market Cap + Total Liabilities ) 8% 31%\nunit USD MM USD MM\nstatements 2011-03 2011-03\nmarket price: last trade of 2011-07 2011-07\nWe have now made the first refinement to our leverage measure. For the next refinement, we improve our value of assets\nestimation. Firm value is one estimate of the value of a firm’s assets. A second estimation is that made by an accountant, where\ntotal assets is the summation of what is paid for when purchasing a company’s assets, after accounting for depreciation and other\naccounting rules. So at the beginning, the total value of a firm’s assets is the total funding provided by the right hand side of the\nbalance sheet. A third estimation comes from a market valuation perspective. In this case, the value of assets comes from the net\npresent value of the future cash flows they generate, reflective of the synergies of the different assets, not a simple summation of\nthem. Therefore, the market value of assets can differ from the value of assets reported in the statements or from the firm value.\nThe market value of assets has two components:\nThe market value of a firm’s liabilities differs from the book value of liabilities. The book value of liabilities is typically the\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴 =𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐸𝐸𝐸𝐸𝑃𝑃𝑂𝑂𝐴𝐴𝐸𝐸+𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐿𝐿𝑂𝑂𝐶𝐶𝑎𝑎𝑂𝑂𝐶𝐶𝑂𝑂𝐴𝐴𝑂𝑂𝐴𝐴𝐴𝐴\ndiscounted value of promised future payments, discounted at the loan’s coupon. As a firm enters financial distress, the market\nvalue of liabilities typically declines, as one could buy the liabilities for less than the book value of the debt. This decline reflects\nthe increasing default risk premium that investors demand in order to hold the risky debt. Therefore, the market value of assets for\na firm in financial distress is typically less than the market capitalization plus the book value of total liabilities. The Public Firm EDF\nmodel estimates this default risk premium and uses it to obtain the market value of assets, a concept similar to Enterprise Value.25\nWe can see the benefit of using the market value of assets in the next example. Six months before its bankruptcy, Lehman\nBrothers Holdings leverage ratio was 3%, using firm value. However, accounting for the default risk premium of Lehman’s\nliabilities, we find its leverage ratio was -15%.\n25 The key difference between enterprise value and what we call the market value of assets is the treatment of cash. In the context of acquisitions, the\nenterprise value of a firm is intended to estimate how much it costs to buy the company debt-free and cash-free. In the context of the our model, the market\nvalue of assets is how much it costs to buy the company debt-free.\n34 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nTable 6\nMarket Cap + Total Liabilities vs. Market Value of Assets\nLEHMAN BROTHERS HOLDINGS BARCLAYS PLC\nMarket Capitalization 19,971 29,752\nTotal Liabilities 637,483 1,129,283\nDefault Risk Premium 105,533 100,611\nMarket Value of Assets 551,921 1,058,424\nMarket Cap / ( Market Cap + Total Liabilities) 3% 2.5%\n( MV of Assets – Total Liabilities ) / MV of Assets26 -15% -7%\nunit USD MM GBP MM\nstatement 2007-08 2007-06\nmarket price: last trade of 2008-03 2008-03\nAt the same time, we see that Barclays’ credit risk is measured as less risky than Lehman’s, only after proper estimation of the\ndefault risk premium and the subsequent estimation of market value of assets.\nFor the third refinement to leverage, we look at total liabilities. Is total liabilities indeed the best measure to compare against asset\nvalue? Relative to current liabilities, long-term liabilities provides firms some breathing room to work through transitory\ndisruptions in cash flow. A firm with more immediate due dates is at higher risk than one with due dates years into the future.\nConsequently, the two measures are not of the same importance in determining default risk at the one-year horizon.\nTake Bombardier for example. Six months before default, its leverage ratio was 22%, as was Bouygues SA. Nevertheless, Bouygues\ndid not default (as of yet). Backed by years of research, we find that the default point is a more suitable value to compare against\nasset values. Indeed, when we define leverage using the default point, we find Bombardier’s leverage to be less than Bouygues’.\nThe so-called default point is defined as current liabilities plus one-half long-term liabilities. Put differently, this study tells us that,\nwhile the market value of assets was dropping, Bombardier had a relatively large portion of its liabilities due in less than a year, and\nthis particular capital structure may have contributed to its default.\nTable 7\nTotal Liabilities vs. Default Point in Construction of Leverage\nBOMBARDIER BOUYGUES SA\nMarket Capitalization 5,403 9,174\nDefault Risk Premium 40 1,244\nShort-Term Liabilities 14,880 18,836\nLong-Term Liabilities 3,873 8,907\nDefault Point 16,816 23,289\nMarket Value of Assets 24,116 35,673\n( MV of Assets – Total Liabilities ) / MV of Assets 22% 22%\n( MV of Assets – Default Point ) / MV of Assets 30% 35%\nunit CAD MM Euro MM\nstatement 2008-10 2008-09\nmarket price: last trade of 2009-01 2009-01\nWe began with a basic measure of leverage and in three steps refined it to use market data, incorporate a default risk premium,\nand take into consideration the relative different importance of short-term and long-term liabilities.\nTo motivate the final refinement, we now ask if this analysis is even fair. Can we legitimately compare the leverage ratio of a\nCanadian airplane and train manufacturer to the leverage ratio of a French construction company? Producing different products,\nthey have different cash flow risks. Involvement with different industries subjects them to different regulatory risks, and,\nadditionally, their assets are subject to different monetary and fiscal policy shocks. These considerations, and many more, affect\nthe firm’s cash flow risk.\n26 It is noteworthy that the leverage measure is not defined as market cap as a percentage of market value of assets. The reason: the chosen ratio penalizes\nhigh credit risk names more than a simple market cap to assets ratio would:\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴=𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝐶𝐶𝐶𝐶𝑂𝑂+𝑇𝑇𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶 𝐿𝐿𝑂𝑂𝐶𝐶𝑎𝑎𝑂𝑂𝐶𝐶𝑂𝑂𝐴𝐴𝑂𝑂𝐴𝐴𝐴𝐴−𝐷𝐷𝐴𝐴𝐷𝐷𝐶𝐶𝑃𝑃𝐶𝐶𝐴𝐴 𝑅𝑅𝑂𝑂𝐴𝐴𝑆𝑆 𝑃𝑃𝑟𝑟𝐴𝐴𝑃𝑃𝑂𝑂𝑃𝑃𝑃𝑃\n𝑀𝑀𝐶𝐶𝑟𝑟𝐴𝐴𝑆𝑆𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴−𝑇𝑇𝑂𝑂𝐴𝐴𝐶𝐶𝐶𝐶 𝐿𝐿𝑂𝑂𝐶𝐶𝑎𝑎𝑂𝑂𝐶𝐶𝑂𝑂𝐴𝐴𝑂𝑂𝐴𝐴𝐴𝐴 𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝐶𝐶𝐶𝐶𝑂𝑂−𝐷𝐷𝐴𝐴𝐷𝐷𝐶𝐶𝑃𝑃𝐶𝐶𝐴𝐴 𝑅𝑅𝑂𝑂𝐴𝐴𝑆𝑆 𝑃𝑃𝑟𝑟𝐴𝐴𝑃𝑃𝑂𝑂𝑃𝑃𝑃𝑃\n=\n35 JUNE 2015 𝑀𝑀𝐶𝐶 𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴 𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶 𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴C𝐴𝐴R𝐴𝐴E𝐴𝐴DIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nA proper rank-ordering of credit risk cannot be achieved without accounting for asset risk. If a bank and a pharmaceutical company\nhave the same market leverage, it does not imply they have the same credit risk, as a bank’s assets are much safer than a\npharmaceutical company’s. If we measure the fluctuations of each firm’s asset returns we can estimate asset volatility as the\nstandard-deviation of asset returns.\nIf we take our refined measure of leverage and adjust it for asset volatility, we get\n𝑀𝑀𝐶𝐶𝑟𝑟𝑆𝑆𝐴𝐴𝐴𝐴 𝑉𝑉𝐶𝐶𝐶𝐶𝑃𝑃𝐴𝐴 𝑂𝑂𝐷𝐷 𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴𝐴−𝐷𝐷𝐴𝐴𝐷𝐷𝐶𝐶𝑃𝑃𝐶𝐶𝐴𝐴 𝑃𝑃𝑂𝑂𝑂𝑂𝑂𝑂𝐴𝐴\nJapan Airlines filed for bankruptcy in Janua𝑀𝑀ry𝐶𝐶 o𝑟𝑟f𝑆𝑆 2𝐴𝐴0𝐴𝐴 1𝑉𝑉0𝐶𝐶. 𝐶𝐶S𝑃𝑃ix𝐴𝐴 m 𝑂𝑂𝐷𝐷on 𝐴𝐴th𝐴𝐴s𝐴𝐴 𝐴𝐴e𝐴𝐴a𝐴𝐴rl ie∙r𝐴𝐴, t𝐴𝐴h𝐴𝐴e𝐴𝐴 𝐴𝐴d i𝑉𝑉ff𝑂𝑂er𝐶𝐶e𝐶𝐶n𝐴𝐴c𝑂𝑂𝐶𝐶e𝑂𝑂 𝐴𝐴b𝐸𝐸etween its market value of assets and\ndefault point, as a percentage of value of assets, was 44%, while the same ratio for Nagoya Railroad, a ground transportation\nbusiness in Japan of comparable size was 42%. The default risk premium in both cases is comparable to their market capitalization.\nIn fact, from this angle, Nagoya’s situation appears a bit worse. When looking at their asset risk, however, we find Japan Airline’s\nasset volatility was 9%, higher than Nagoya’s 6%. A business model working with high-risk assets, for the chosen capital structure,\nultimately jeopardized the business.\nTable 8\nMarket Leverage vs. Risk-Adjusted Market Leverage\nJAPAN AIRLINES NAGOYA RAILROAD\nMarket Capitalization 440 277\nDefault Risk Premium 413 282\nShort-Term Liabilities 679 483\nLong-Term Liabilities 970 463\nDefault Point 1,164 714\nMarket Value of Assets 2,062 1,228\nAsset Volatility 9% 6%\n( MV of Assets – Default Point ) / MV of Assets 44% 42%\n( MV of Assets – Default Point ) / MV of Assets * Asset Volatility 4.8 6.9\nUnit Billions of JPY Billions of JPY\nStatement 2008-12 2008-12\nmarket price: last trade of 2009-07 2009-07\nAs our risk-adjusted measure of market leverage indicates, Japan Airlines was indeed riskier than Nagoya during the months\npreceding the credit event.\nWe have now constructed a heuristic version of DD using market value of assets, default point, and asset volatility. This ratio\neffectively describes the distance of the firm from default in standard deviation units. In the context of our model, the default\npoint is the point where creditors lose faith in the firm’s ability to service its current obligation, stop extending credit, and push the\nfirm into default. So the point where the market value of assets reaches the default point is important. On the other hand, as time\ngoes by, what regulates asset values’ ups and downs is asset volatility. Given leverage, the more volatile the assets, the more likely\nit is that their value crosses the default point in the future. In other words, what we are interested in is the gap between the market\nvalue of assets and the default point, as a percentage of asset value fluctuations, and that is precisely what our updated leverage\nmeasure shows.\nIt is at first surprising that a single model can produce such reliable measures of credit risk for more than 35,000 different firms,\nacross such varied countries and business activities. But part of the model’s effectiveness in rank-ordering is in separately\ncalculating the market leverage of each firm, as well as its asset risks; coming up with an individualized DD that properly controls\nfor the factors relevant to credit risk.\nWhile the tables above reported ratios in percentages, the last table reports the DD of JAL and Nagoya as simply 4.8 and 6.9,\nrespectively. The units are standard deviations, so they are not yet useful for computing the expected default frequency of an\nindividual name or the expected loss rate of a portfolio. To rectify this issue, we transform the DD to the physical probability\nspace, and call it the EDF credit metric. This process is further described in Section 4.\nThe Public Firm EDF model measures a specific aspect of credit risk — the physical probability of default — contrasted with credit\ndefault swaps, whose spread reflects loss given default, as well as the risk-neutral probability of default. Moreover, EDF measures\n36 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nreflect a firm’s stand-alone credit risk without the aid of government support (e.g. a government bailout). The EDF credit measure\nis a scaled metric, meaning its absolute value has an objective interpretation. Consequently, the EDF credit measure has cyclical\nproperties, thereby reflecting changes in systematic default risk. On the other hand, ratings published by Moody’s Investors Service\nprovide “relative credit worthiness” (page 2, Moody’s Investors Service, 2004) as an ordinal measure. An agency rating may remain\nstable through a credit cycle, yet the default risk of a rating, for instance a Baa3, will be cyclic. Furthermore, as the market value of\nequity is a primary driver, EDF value is not directly impacted by the liquidity of the bond market or the CDS market.\n37 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nAppendix C Calibration Sample Size Cuts\nThis appendix explains the size cuts used to construct different samples against which we test the DD to EDF calibration.\nIn order to capture the population of top-90%, once a month and in each region, we sort firms by size from large to small, and\nchoose until we have 90% of the outstanding total liabilities of that region for that month. In other words, the model is calibrated\nto where 90% of credit risk resides, as well as for rated firms.\nFigure 15 Size of the 90%, 99%, and 99.9% Cuts, Non-Financial Corporations\n38 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nFigure 16 Size of the 90%, 99%, and 99.9% Cuts, Financial Firms\nFor non-financial corporations, the top-90% cut-off roughly coincides with a size of about two billion dollars. For financials, the\ncut-off is closer to twenty billion dollars. The two figures above show the relation between size and the 90%, 99%, and 99.9% cut-\noffs, where size is the average of book value of assets and sales.\n39 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nReferences\nArora, Navneet, Jeffery Bohn, and Irina Korablev, “Power and Level Validation of the EDF Credit Measure in the U.S. Market.”\nMoody’s KMV, 2005.\nArora, Navneet, Jeffery Bohn, and Fanlin Zhu, “Reduced Form vs. Structural Models of Credit Risk: A Case Study of Three Models.”\nJournal of Investment Management, Vol.3, No.4, Fourth Quarter 2005.\nBasel Committee on Banking Supervision, “International Convergence of Capital Measurement and Capital Standards (‘A Revised\nFramework’).” Bank for International Settlements, 2004.\nBlack, Fischer and John C. Cox, “Valuing Corporate Securities: Some Effects of Bond Indenture Provisions.” The Journal of Finance\n31:351-367, 1976.\nBohn, Jeffrey R. and Roger M. Stein, Active Credit Portfolio Management in Practice. Vol. 384. John Wiley & Sons, 2009.\nCantor, Richard and Chris Mann, “Analyzing the Tradeoff Between Ratings Accuracy and Stability.” Moody’s Investors Service,\nSeptember 2006.\nCaouette, John B., Edward I. Altman, Paul Narayanan, and Robert Nimmo, Managing Credit Risk: The Great Challenge for Global\nFinancial Markets. Vol. 401. John Wiley & Sons, 2011.\nChen, Nan, Houman Dehghan, Min Ding, Jian Du, James Edwards, Danielle Ferry, Pooya Nazeran, Sue Zhang, Douglas Dwyer, and\nJing Zhang, “EDF9: Introduction Overview.” Moody’s Analytics White Paper, February 2015.\nCrosbie, Peter and Jeff Bohn, “Modeling Default Risk.” Moody’s KMV White Paper, December 2003.\nDuffie, Darrell and Kenneth J. Singleton, Credit Risk: Pricing, Measurement, and Management: Pricing, Measurement, and\nManagement. Princeton University Press, 2012.\nDwyer, Douglas and Shisheng Qu, “EDF 8.0 Model Enhancements.” Moody’s KMV, January 2007.\nEngelmann, Bernd, Evelyn, Hayden, and Dirk Tasche, “Testing Rating Accuracy.“ Risk, January 2003.\nHuang, Jummy, Mariano Lanfranconi, Nihil Patel, and Libor Pospisil, “Modeling Credit Correlations: An Overview of the Moody’s\nAnalytics GCorr Model.” Moody’s Analytics White Paper, December 2012.\nKealhofer, Stephen, “Quantifying Credit Risk I: Default Prediction.” Financial Analysts Journal, January/February 2003, 30-44.\nKealhofer, Stephen and Matthew Kurbatt, “Predictive Merton Models.” Risk, February 2002.\nKnowledge Base FAQ 388, “Estimation of Short- and Long-Term Liabilities.” Moody’s KMV, May 2006\nKnowledge Base FAQ 438, “What Goes into Asset Volatility and Asset Value Calculations?” Moody’s KMV, April 2009.\nKorablev, Irina, “Power and Level Validation of the EDF Credit Measure in the European Market.” Moody’s KMV 2005.\nLeland, H.E, “Corporate Debt Value, Bond Covenants, and Optimal Capital Structure.” The Journal of Finance 49(4), 1994.\nMiller, Ross, “Refining Ratings.” Risk, August 1998.\nMoody’s Analytics, “Public EDF Validation.” Moody’s Analytics, March 2015.\nRanson, Brian J., Credit Risk Management. Sheshunoff/Alex eSolutions, 2005.\n40 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\nStein, Roger, “Evidence on the Incompleteness of Merton-Type Structural Models for Default Prediction.” Moody’s KMV, 2005.\nThis paper is a revised version of the Moody’s Risk Management Services paper from 2000.\nSun, Zhao, David Munves, and David Hamilton, “Public Firm Expected Default Frequency (EDF) Credit Measures: Methodology,\nPerformance, and Model Extensions.” Moody’s Analytics White Paper, 2012.\nVasicek, Oldrick, “A Note on Using Cross-Sectional Information in Bayesian Estimation of Security Betas.” Journal of Finance, Vol.\n29, May, 449-470, 1974.\n41 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9QUANTITATIVE RESEARCH GROUP\n© Copyright 2015 Moody’s Corporation, Moody’s Investors Service, Inc., Moody’s Analytics, Inc. and/or their licensors and affiliates (collectively, “MOODY’S”). All rights reserved.\nCREDIT RATINGS ISSUED BY MOODY'S INVESTORS SERVICE, INC. (“MIS”) AND ITS AFFILIATES ARE MOODY’S CURRENT OPINIONS OF THE RELATIVE FUTURE CREDIT RISK OF\nENTITIES, CREDIT COMMITMENTS, OR DEBT OR DEBT-LIKE SECURITIES, AND CREDIT RATINGS AND RESEARCH PUBLICATIONS PUBLISHED BY MOODY’S (“MOODY’S\nPUBLICATIONS”) MAY INCLUDE MOODY’S CURRENT OPINIONS OF THE RELATIVE FUTURE CREDIT RISK OF ENTITIES, CREDIT COMMITMENTS, OR DEBT OR DEBT-LIKE\nSECURITIES. MOODY’S DEFINES CREDIT RISK AS THE RISK THAT AN ENTITY MAY NOT MEET ITS CONTRACTUAL, FINANCIAL OBLIGATIONS AS THEY COME DUE AND ANY\nESTIMATED FINANCIAL LOSS IN THE EVENT OF DEFAULT. CREDIT RATINGS DO NOT ADDRESS ANY OTHER RISK, INCLUDING BUT NOT LIMITED TO: LIQUIDITY RISK, MARKET\nVALUE RISK, OR PRICE VOLATILITY. CREDIT RATINGS AND MOODY’S OPINIONS INCLUDED IN MOODY’S PUBLICATIONS ARE NOT STATEMENTS OF CURRENT OR HISTORICAL\nFACT. MOODY’S PUBLICATIONS MAY ALSO INCLUDE QUANTITATIVE MODEL-BASED ESTIMATES OF CREDIT RISK AND RELATED OPINIONS OR COMMENTARY PUBLISHED BY\nMOODY’S ANALYTICS, INC. CREDIT RATINGS AND MOODY’S PUBLICATIONS DO NOT CONSTITUTE OR PROVIDE INVESTMENT OR FINANCIAL ADVICE, AND CREDIT RATINGS\nAND MOODY’S PUBLICATIONS ARE NOT AND DO NOT PROVIDE RECOMMENDATIONS TO PURCHASE, SELL, OR HOLD PARTICULAR SECURITIES. NEITHER CREDIT RATINGS\nNOR MOODY’S PUBLICATIONS COMMENT ON THE SUITABILITY OF AN INVESTMENT FOR ANY PARTICULAR INVESTOR. MOODY’S ISSUES ITS CREDIT RATINGS AND\nPUBLISHES MOODY’S PUBLICATIONS WITH THE EXPECTATION AND UNDERSTANDING THAT EACH INVESTOR WILL, WITH DUE CARE, MAKE ITS OWN STUDY AND\nEVALUATION OF EACH SECURITY THAT IS UNDER CONSIDERATION FOR PURCHASE, HOLDING, OR SALE.\nMOODY’S CREDIT RATINGS AND MOODY’S PUBLICATIONS ARE NOT INTENDED FOR USE BY RETAIL INVESTORS AND IT WOULD BE RECKLESS FOR RETAIL INVESTORS TO\nCONSIDER MOODY’S CREDIT RATINGS OR MOODY’S PUBLICATIONS IN MAKING ANY INVESTMENT DECISION. IF IN DOUBT YOU SHOULD CONTACT YOUR FINANCIAL OR\nOTHER PROFESSIONAL ADVISER.\nALL INFORMATION CONTAINED HEREIN IS PROTECTED BY LAW, INCLUDING BUT NOT LIMITED TO, COPYRIGHT LAW, AND NONE OF SUCH INFORMATION MAY BE COPIED\nOR OTHERWISE REPRODUCED, REPACKAGED, FURTHER TRANSMITTED, TRANSFERRED, DISSEMINATED, REDISTRIBUTED OR RESOLD, OR STORED FOR SUBSEQUENT USE FOR\nANY SUCH PURPOSE, IN WHOLE OR IN PART, IN ANY FORM OR MANNER OR BY ANY MEANS WHATSOEVER, BY ANY PERSON WITHOUT MOODY’S PRIOR WRITTEN\nCONSENT.\nAll information contained herein is obtained by MOODY’S from sources believed by it to be accurate and reliable. Because of the possibility of human or mechanical error as well as\nother factors, however, all information contained herein is provided “AS IS” without warranty of any kind. MOODY'S adopts all necessary measures so that the information it uses in\nassigning a credit rating is of sufficient quality and from sources MOODY'S considers to be reliable including, when appropriate, independent third-party sources. However,\nMOODY’S is not an auditor and cannot in every instance independently verify or validate information received in the rating process or in preparing the Moody’s Publications.\nTo the extent permitted by law, MOODY’S and its directors, officers, employees, agents, representatives, licensors and suppliers disclaim liability to any person or entity for any\nindirect, special, consequential, or incidental losses or damages whatsoever arising from or in connection with the information contained herein or the use of or inability to use any\nsuch information, even if MOODY’S or any of its directors, officers, employees, agents, representatives, licensors or suppliers is advised in advance of the possibility of such losses or\ndamages, including but not limited to: (a) any loss of present or prospective profits or (b) any loss or damage arising where the relevant financial instrument is not the subject of a\nparticular credit rating assigned by MOODY’S.\nTo the extent permitted by law, MOODY’S and its directors, officers, employees, agents, representatives, licensors and suppliers disclaim liability for any direct or compensatory\nlosses or damages caused to any person or entity, including but not limited to by any negligence (but excluding fraud, willful misconduct or any other type of liability that, for the\navoidance of doubt, by law cannot be excluded) on the part of, or any contingency within or beyond the control of, MOODY’S or any of its directors, officers, employees, agents,\nrepresentatives, licensors or suppliers, arising from or in connection with the information contained herein or the use of or inability to use any such information.\nNO WARRANTY, EXPRESS OR IMPLIED, AS TO THE ACCURACY, TIMELINESS, COMPLETENESS, MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OF ANY SUCH\nRATING OR OTHER OPINION OR INFORMATION IS GIVEN OR MADE BY MOODY’S IN ANY FORM OR MANNER WHATSOEVER.\nMIS, a wholly-owned credit rating agency subsidiary of Moody’s Corporation (“MCO”), hereby discloses that most issuers of debt securities (including corporate and municipal\nbonds, debentures, notes and commercial paper) and preferred stock rated by MIS have, prior to assignment of any rating, agreed to pay to MIS for appraisal and rating services\nrendered by it fees ranging from $1,500 to approximately $2,500,000. MCO and MIS also maintain policies and procedures to address the independence of MIS’s ratings and rating\nprocesses. Information regarding certain affiliations that may exist between directors of MCO and rated entities, and between entities who hold ratings from MIS and have also\npublicly reported to the SEC an ownership interest in MCO of more than 5%, is posted annually at www.moodys.com under the heading “Shareholder Relations — Corporate\nGovernance — Director and Shareholder Affiliation Policy.”\nFor Australia only: Any publication into Australia of this document is pursuant to the Australian Financial Services License of MOODY’S affiliate, Moody’s Investors Service Pty\nLimited ABN 61 003 399 657AFSL 336969 and/or Moody’s Analytics Australia Pty Ltd ABN 94 105 136 972 AFSL 383569 (as applicable). This document is intended to be provided\nonly to “wholesale clients” within the meaning of section 761G of the Corporations Act 2001. By continuing to access this document from within Australia, you represent to\nMOODY’S that you are, or are accessing the document as a representative of, a “wholesale client” and that neither you nor the entity you represent will directly or indirectly\ndisseminate this document or its contents to “retail clients” within the meaning of section 761G of the Corporations Act 2001. MOODY’S credit rating is an opinion as to the\ncreditworthiness of a debt obligation of the issuer, not on the equity securities of the issuer or any form of security that is available to retail clients. It would be dangerous for “retail\nclients” to make any investment decision based on MOODY’S credit rating. If in doubt you should contact your financial or other professional adviser.\n42 JUNE 2015 CREDIT RISK MODELING OF PUBLIC FIRMS: EDF9"
}